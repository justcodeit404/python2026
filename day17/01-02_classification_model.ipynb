{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对应 `tf.keras` 的01~02章节"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:22.595848Z",
     "start_time": "2026-02-09T17:40:56.644792Z"
    }
   },
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, torch:\n",
    "    print(module.__name__, module.__version__)\n",
    "    \n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=12, micro=7, releaselevel='final', serial=0)\n",
      "matplotlib 3.9.2\n",
      "numpy 1.26.4\n",
      "pandas 2.2.2\n",
      "sklearn 1.5.1\n",
      "torch 2.6.0+cu126\n",
      "cuda:0\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "28*28"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:22.610756Z",
     "start_time": "2026-02-09T17:41:22.603874Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:24.901886Z",
     "start_time": "2026-02-09T17:41:22.692913Z"
    }
   },
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# 定义数据集的变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 转换为tensor，进行归一化\n",
    "    # transforms.Normalize(mean, std) # 标准化，mean和std是数据集的均值和方差\n",
    "])\n",
    "# fashion_mnist图像分类数据集，衣服分类，60000张训练图片，10000张测试图片\n",
    "train_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_ds = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# torchvision 数据集里没有提供训练集和验证集的划分\n",
    "# 当然也可以用 torch.utils.data.Dataset 实现人为划分"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "type(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:24.915813Z",
     "start_time": "2026-02-09T17:41:24.909947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.FashionMNIST"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:24.945245Z",
     "start_time": "2026-02-09T17:41:24.940485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "type(train_ds[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:24.964471Z",
     "start_time": "2026-02-09T17:41:24.958645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:24.992848Z",
     "start_time": "2026-02-09T17:41:24.987450Z"
    }
   },
   "source": [
    "# 通过id取数据，取到的是一个元祖,是第一个样本,在训练时，把特征和标签分开\n",
    "img, label = train_ds[0]\n",
    "img.shape\n",
    "# img.shape = (1, 28, 28)，这是因为通道数在最前面"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:25.025389Z",
     "start_time": "2026-02-09T17:41:25.019785Z"
    }
   },
   "cell_type": "code",
   "source": "type(img) #tensor中文是 张量,和numpy的ndarray类似",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "img[0]",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:25.062816Z",
     "start_time": "2026-02-09T17:41:25.053104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510, 0.2863, 0.0000,\n",
       "         0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0039,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333, 0.4980, 0.2431,\n",
       "         0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118, 0.0157, 0.0000, 0.0000,\n",
       "         0.0118],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000, 0.6902, 0.5255,\n",
       "         0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0471, 0.0392,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255, 0.8118, 0.6980,\n",
       "         0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902, 0.3020, 0.5098, 0.2824,\n",
       "         0.0588],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745, 0.8549, 0.8471,\n",
       "         0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725, 0.5529, 0.3451, 0.6745,\n",
       "         0.2588],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098, 0.9137, 0.8980,\n",
       "         0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980, 0.4824, 0.7686, 0.8980,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471, 0.8745, 0.8941,\n",
       "         0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667, 0.8745, 0.9608, 0.6784,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549, 0.8353, 0.7765,\n",
       "         0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745, 0.8627, 0.9529, 0.7922,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314, 0.8549, 0.7529,\n",
       "         0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314, 0.8863, 0.7725, 0.8196,\n",
       "         0.2039],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627, 0.8549, 0.7961,\n",
       "         0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627, 0.9608, 0.4667, 0.6549,\n",
       "         0.2196],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020, 0.8941, 0.9412,\n",
       "         0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510, 0.8510, 0.8196, 0.3608,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745, 0.8706, 0.8588,\n",
       "         0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431, 0.8549, 1.0000, 0.3020,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667, 0.8549, 0.8157,\n",
       "         0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431, 0.8784, 0.9569, 0.6235,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196, 0.7412,\n",
       "         0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039, 0.8275, 0.9020,\n",
       "         0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725, 0.9137, 0.9333, 0.8431,\n",
       "         0.0000],\n",
       "        [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157, 0.8000,\n",
       "         0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569, 0.8078, 0.8745,\n",
       "         1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275, 0.8627, 0.9098, 0.9647,\n",
       "         0.0000],\n",
       "        [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392, 0.8039,\n",
       "         0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000, 0.8980, 0.8667,\n",
       "         0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196, 0.8706, 0.8941, 0.8824,\n",
       "         0.0000],\n",
       "        [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176, 0.9765,\n",
       "         0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863, 0.4157, 0.4588,\n",
       "         0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745, 0.8745, 0.8784, 0.8980,\n",
       "         0.1137],\n",
       "        [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824, 0.8471,\n",
       "         0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647, 0.8902, 0.9608,\n",
       "         0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706, 0.8627, 0.8667, 0.9020,\n",
       "         0.2627],\n",
       "        [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451, 0.7608,\n",
       "         0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255, 0.8824, 0.8471,\n",
       "         0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745, 0.7098, 0.8039, 0.8078,\n",
       "         0.4510],\n",
       "        [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686, 0.8000,\n",
       "         0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686, 0.7608, 0.7490,\n",
       "         0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118, 0.6549, 0.6941, 0.8235,\n",
       "         0.3608],\n",
       "        [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745, 0.6863,\n",
       "         0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765, 0.8000, 0.8196,\n",
       "         0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608, 0.7529, 0.8471, 0.6667,\n",
       "         0.0000],\n",
       "        [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294, 0.9373,\n",
       "         0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569, 0.7490, 0.7020,\n",
       "         0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588, 0.3882, 0.2275, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569, 0.2392,\n",
       "         0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:25.108446Z",
     "start_time": "2026-02-09T17:41:25.097225Z"
    }
   },
   "cell_type": "code",
   "source": "img",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "          0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "          0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "          0.0157, 0.0000, 0.0000, 0.0118],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "          0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0471, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "          0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "          0.3020, 0.5098, 0.2824, 0.0588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "          0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "          0.5529, 0.3451, 0.6745, 0.2588],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "          0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "          0.4824, 0.7686, 0.8980, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "          0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "          0.8745, 0.9608, 0.6784, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "          0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "          0.8627, 0.9529, 0.7922, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "          0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "          0.8863, 0.7725, 0.8196, 0.2039],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "          0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "          0.9608, 0.4667, 0.6549, 0.2196],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "          0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "          0.8510, 0.8196, 0.3608, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "          0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "          0.8549, 1.0000, 0.3020, 0.0000],\n",
       "         [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "          0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "          0.8784, 0.9569, 0.6235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "          0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "          0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "          0.9137, 0.9333, 0.8431, 0.0000],\n",
       "         [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "          0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "          0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "          0.8627, 0.9098, 0.9647, 0.0000],\n",
       "         [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "          0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "          0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "          0.8706, 0.8941, 0.8824, 0.0000],\n",
       "         [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "          0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "          0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "          0.8745, 0.8784, 0.8980, 0.1137],\n",
       "         [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "          0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "          0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "          0.8627, 0.8667, 0.9020, 0.2627],\n",
       "         [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "          0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "          0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "          0.7098, 0.8039, 0.8078, 0.4510],\n",
       "         [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "          0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "          0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "          0.6549, 0.6941, 0.8235, 0.3608],\n",
       "         [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "          0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "          0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "          0.7529, 0.8471, 0.6667, 0.0000],\n",
       "         [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "          0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "          0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "          0.3882, 0.2275, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "          0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "#计算均值和方差\n",
    "def cal_mean_std(ds):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for img, _ in ds: # 遍历每张图片,img.shape=[1,28,28]\n",
    "        mean += img.mean(dim=(1, 2))\n",
    "        std += img.std(dim=(1, 2))\n",
    "    mean /= len(ds)\n",
    "    std /= len(ds)\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "print(cal_mean_std(train_ds))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.403390Z",
     "start_time": "2026-02-09T17:41:25.318995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.2860]), tensor([0.3205]))\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "type(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.451919Z",
     "start_time": "2026-02-09T17:41:33.446527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.471812Z",
     "start_time": "2026-02-09T17:41:33.466805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "type(img) #tensor中文是 张量,和numpy的ndarray类似"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.503904Z",
     "start_time": "2026-02-09T17:41:33.499072Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "label"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.675318Z",
     "start_time": "2026-02-09T17:41:33.669897Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# 显示图片，这里需要把transforms.ToTensor(),进行归一化注释掉，否则是不行的\n",
    "def show_img_content(img):\n",
    "    from PIL import Image\n",
    "\n",
    "    # 打开一个图像文件\n",
    "    # img = Image.open(img)\n",
    "\n",
    "\n",
    "    print(\"图像大小:\", img.size)\n",
    "    print(\"图像模式:\", img.mode)\n",
    "\n",
    "\n",
    "    # 如果图像是单通道的，比如灰度图，你可以这样获取像素值列表：\n",
    "    if img.mode == 'L':\n",
    "        pixel_values = list(img.getdata())\n",
    "        print(pixel_values)\n",
    "show_img_content(img) #这里必须把上面的 transforms.ToTensor(), # 转换为tensor，进行归一化注释掉，否则是不行的"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:33.725153Z",
     "start_time": "2026-02-09T17:41:33.720178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像大小: <built-in method size of Tensor object at 0x00000184C061D5E0>\n",
      "图像模式: <built-in method mode of Tensor object at 0x00000184C061D5E0>\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "#这个代码必须是注释了上面的 transforms.ToTensor()才能够运行的\n",
    "def show_single_image(img_arr):\n",
    "    plt.imshow(img_arr, cmap=\"binary\") # 显示图片\n",
    "    plt.colorbar() # 显示颜色条\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "show_single_image(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.621365Z",
     "start_time": "2026-02-09T17:41:33.768249Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (1, 28, 28) for image data",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 8\u001B[0m\n\u001B[0;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mcolorbar() \u001B[38;5;66;03m# 显示颜色条\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m----> 8\u001B[0m show_single_image(img)\n",
      "Cell \u001B[1;32mIn[17], line 3\u001B[0m, in \u001B[0;36mshow_single_image\u001B[1;34m(img_arr)\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mshow_single_image\u001B[39m(img_arr):\n\u001B[1;32m----> 3\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(img_arr, cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;66;03m# 显示图片\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     plt\u001B[38;5;241m.\u001B[39mcolorbar() \u001B[38;5;66;03m# 显示颜色条\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\pyplot.py:3562\u001B[0m, in \u001B[0;36mimshow\u001B[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001B[0m\n\u001B[0;32m   3541\u001B[0m \u001B[38;5;129m@_copy_docstring_and_deprecators\u001B[39m(Axes\u001B[38;5;241m.\u001B[39mimshow)\n\u001B[0;32m   3542\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mimshow\u001B[39m(\n\u001B[0;32m   3543\u001B[0m     X: ArrayLike \u001B[38;5;241m|\u001B[39m PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3560\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3561\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m AxesImage:\n\u001B[1;32m-> 3562\u001B[0m     __ret \u001B[38;5;241m=\u001B[39m gca()\u001B[38;5;241m.\u001B[39mimshow(\n\u001B[0;32m   3563\u001B[0m         X,\n\u001B[0;32m   3564\u001B[0m         cmap\u001B[38;5;241m=\u001B[39mcmap,\n\u001B[0;32m   3565\u001B[0m         norm\u001B[38;5;241m=\u001B[39mnorm,\n\u001B[0;32m   3566\u001B[0m         aspect\u001B[38;5;241m=\u001B[39maspect,\n\u001B[0;32m   3567\u001B[0m         interpolation\u001B[38;5;241m=\u001B[39minterpolation,\n\u001B[0;32m   3568\u001B[0m         alpha\u001B[38;5;241m=\u001B[39malpha,\n\u001B[0;32m   3569\u001B[0m         vmin\u001B[38;5;241m=\u001B[39mvmin,\n\u001B[0;32m   3570\u001B[0m         vmax\u001B[38;5;241m=\u001B[39mvmax,\n\u001B[0;32m   3571\u001B[0m         origin\u001B[38;5;241m=\u001B[39morigin,\n\u001B[0;32m   3572\u001B[0m         extent\u001B[38;5;241m=\u001B[39mextent,\n\u001B[0;32m   3573\u001B[0m         interpolation_stage\u001B[38;5;241m=\u001B[39minterpolation_stage,\n\u001B[0;32m   3574\u001B[0m         filternorm\u001B[38;5;241m=\u001B[39mfilternorm,\n\u001B[0;32m   3575\u001B[0m         filterrad\u001B[38;5;241m=\u001B[39mfilterrad,\n\u001B[0;32m   3576\u001B[0m         resample\u001B[38;5;241m=\u001B[39mresample,\n\u001B[0;32m   3577\u001B[0m         url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   3578\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m: data} \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m {}),\n\u001B[0;32m   3579\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   3580\u001B[0m     )\n\u001B[0;32m   3581\u001B[0m     sci(__ret)\n\u001B[0;32m   3582\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m __ret\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:1473\u001B[0m, in \u001B[0;36m_preprocess_data.<locals>.inner\u001B[1;34m(ax, data, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1470\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m   1471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minner\u001B[39m(ax, \u001B[38;5;241m*\u001B[39margs, data\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m   1472\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1473\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\n\u001B[0;32m   1474\u001B[0m             ax,\n\u001B[0;32m   1475\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mmap\u001B[39m(sanitize_sequence, args),\n\u001B[0;32m   1476\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{k: sanitize_sequence(v) \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems()})\n\u001B[0;32m   1478\u001B[0m     bound \u001B[38;5;241m=\u001B[39m new_sig\u001B[38;5;241m.\u001B[39mbind(ax, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1479\u001B[0m     auto_label \u001B[38;5;241m=\u001B[39m (bound\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mget(label_namer)\n\u001B[0;32m   1480\u001B[0m                   \u001B[38;5;129;01mor\u001B[39;00m bound\u001B[38;5;241m.\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(label_namer))\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:5895\u001B[0m, in \u001B[0;36mAxes.imshow\u001B[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001B[0m\n\u001B[0;32m   5892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aspect \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5893\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_aspect(aspect)\n\u001B[1;32m-> 5895\u001B[0m im\u001B[38;5;241m.\u001B[39mset_data(X)\n\u001B[0;32m   5896\u001B[0m im\u001B[38;5;241m.\u001B[39mset_alpha(alpha)\n\u001B[0;32m   5897\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m im\u001B[38;5;241m.\u001B[39mget_clip_path() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   5898\u001B[0m     \u001B[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:729\u001B[0m, in \u001B[0;36m_ImageBase.set_data\u001B[1;34m(self, A)\u001B[0m\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(A, PIL\u001B[38;5;241m.\u001B[39mImage\u001B[38;5;241m.\u001B[39mImage):\n\u001B[0;32m    728\u001B[0m     A \u001B[38;5;241m=\u001B[39m pil_to_array(A)  \u001B[38;5;66;03m# Needed e.g. to apply png palette.\u001B[39;00m\n\u001B[1;32m--> 729\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_A \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_normalize_image_array(A)\n\u001B[0;32m    730\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_imcache \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    731\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\matplotlib\\image.py:697\u001B[0m, in \u001B[0;36m_ImageBase._normalize_image_array\u001B[1;34m(A)\u001B[0m\n\u001B[0;32m    695\u001B[0m     A \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001B[39;00m\n\u001B[0;32m    696\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m A\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m]):\n\u001B[1;32m--> 697\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mA\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m for image data\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m A\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# If the input data has values outside the valid range (after\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001B[39;00m\n\u001B[0;32m    701\u001B[0m     \u001B[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001B[39;00m\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;66;03m# making reliable interpretation impossible.\u001B[39;00m\n\u001B[0;32m    703\u001B[0m     high \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m255\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m np\u001B[38;5;241m.\u001B[39missubdtype(A\u001B[38;5;241m.\u001B[39mdtype, np\u001B[38;5;241m.\u001B[39minteger) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: Invalid shape (1, 28, 28) for image data"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.629606800Z",
     "start_time": "2026-02-08T18:44:21.014758Z"
    }
   },
   "source": [
    "def show_imgs(n_rows, n_cols, train_ds, class_names):\n",
    "    assert n_rows * n_cols < len(train_ds)  #确保打印的图片小于总样本数\n",
    "    plt.figure(figsize = (n_cols * 1.4, n_rows * 1.6))  #宽1.4高1.6，宽，高\n",
    "    for row in range(n_rows):\n",
    "        for col in range(n_cols):\n",
    "            index = n_cols * row + col  # 计算索引，从0开始\n",
    "            plt.subplot(n_rows, n_cols, index+1)#因为从1开始\n",
    "            img_arr, label = train_ds[index]\n",
    "            img_arr = np.transpose(img_arr, (1, 2, 0))  # 通道换到最后一维\n",
    "            plt.imshow(img_arr, cmap=\"binary\",\n",
    "                       interpolation = 'nearest')#interpolation='nearest'是临近插值\n",
    "            plt.axis('off')#去除坐标系\n",
    "            plt.title(class_names[label]) # 显示类别名称\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "#已知的图片类别\n",
    "# lables在这个路径https://github.com/zalandoresearch/fashion-mnist\n",
    "class_names = ['T-shirt', 'Trouser', 'Pullover', 'Dress',\n",
    "               'Coat', 'Sandal', 'Shirt', 'Sneaker',\n",
    "               'Bag', 'Ankle boot'] #0-9分别代表的类别\n",
    "#只是打印了前15个样本\n",
    "show_imgs(3, 5, train_ds, class_names)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 700x480 with 15 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGKCAYAAAAWvavcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB5wElEQVR4nO2debxP1f7/XyeO6RzTGcyzTIWQIVOIMpyjEkoqNODekurWLXUvGrgiUulGN2MDIaJU5mMoEgmRkgwl85Q50/r90e+s73u9z9nbx3Gmfc7r+Xj06L3PXp+992evvfZnWa/3EGaMMSCEEEIICSBXZfQFEEIIIYSkFE5kCCGEEBJYOJEhhBBCSGDhRIYQQgghgYUTGUIIIYQEFk5kCCGEEBJYOJEhhBBCSGDhRIYQQgghgYUTGUIIIYQEliueyLzxxhsICwtD9erVr/hievTogcjIyEu2a968OZo3b37F57vc86YFkydPxmuvvZYh575SwsLCQvpvyZIlKT5HuXLlEB8ff8l2S5YsuaxzBfm+pxbsv6zHxIkTnb7LkycPihUrhhYtWmDIkCHYv39/Rl8iEXAMpg45r/QA48ePBwBs2rQJq1atQoMGDa74orITkydPxsaNG/H4449n9KVcNitXrnS2X3rpJSQkJGDx4sXO36+55po0v5Y6depg5cqVIZ8ryPc9tWD/ZV0mTJiAqlWr4ty5c9i/fz++/PJLDB06FMOHD8fUqVPRqlWrjL5EAo7B1OKKJjJr1qzB+vXrERcXh88++wzjxo3jRCYbccMNNzjbsbGxuOqqq5L8PT0oUKBASOc9deoU8uXLlw5XlPlh/2Vdqlevjrp169rtjh074oknnkCTJk1wxx134Oeff0bRokWT/SzvcfrBMZg6XJG0NG7cOADAyy+/jEaNGuHDDz/EqVOnnDY7duxAWFgYhg8fjldffRXly5dHZGQkGjZsiK+//vqS5/jqq68QExOD+Ph4nDx50rPd2bNnMWjQIFStWhW5c+dGbGws7r//fhw4cCDk77Np0ya0bNkSERERiI2NRZ8+fZJ8nzNnzuDZZ59F+fLlkStXLpQsWRKPPPIIjh496rS7ePEihg0bZq+nSJEi6NatG3bt2mXbNG/eHJ999hl27tzpLCNmF7Zt24YuXbqgRIkSyJ07N4oWLYqWLVti3bp1SdrOnTsXderUQd68eVG1alW7EphIcsuiiZLh999/j1tuuQX58+dHy5Yts/19Ty3Yf8GiTJkyGDFiBI4fP463334bgPc9BkJ/py5evBjNmzdHdHQ08ubNizJlyqBjx47Ou3P06NG47rrrEBkZifz586Nq1ap47rnn0u/LZ1E4Bv8ixSsyp0+fxpQpU1CvXj1Ur14dDzzwAB566CFMnz4d3bt3T9L+v//9L6pWrWo1tf79+6Ndu3bYvn07ChYsmOw5pk2bhm7duuGBBx7AqFGjkCNHjmTbXbx4EbfddhuWL1+Op59+Go0aNcLOnTsxcOBANG/eHGvWrEHevHl9v8+5c+fQrl079O7dG/369cOKFSswaNAg7Ny5E59++ikAwBiD22+/HYsWLcKzzz6Lpk2bYsOGDRg4cCBWrlyJlStXInfu3ACAv//97/jf//6HPn36ID4+Hjt27ED//v2xZMkSrF27FjExMXjrrbfQq1cv/PLLL/j4449DvfVZhnbt2uHChQsYNmwYypQpg4MHD2LFihVJJoXr16/Hk08+iX79+qFo0aIYO3YsHnzwQVx99dW48cYbfc9x9uxZ3HrrrbZfz58/j1KlSmXr+55asP+CR7t27ZAjRw4sW7bM/i25exzqO3XHjh2Ii4tD06ZNMX78eBQqVAi///475s6di7NnzyJfvnz48MMP8fDDD+PRRx/F8OHDcdVVV2Hr1q344YcfMvBOZA04Bv8/JoW8++67BoAZM2aMMcaY48ePm8jISNO0aVOn3fbt2w0AU6NGDXP+/Hn792+++cYAMFOmTLF/6969u4mIiDDGGPPyyy+bHDlymKFDhyY5d7NmzUyzZs3s9pQpUwwAM2PGDKfd6tWrDQDz1ltv+X6X7t27GwDm9ddfd/4+ePBgA8B8+eWXxhhj5s6dawCYYcOGOe2mTp1qAJj//e9/xhhjNm/ebACYhx9+2Gm3atUqA8A899xz9m9xcXGmbNmyvtcXFGT/XYqDBw8aAOa1117zbVe2bFmTJ08es3PnTvu306dPm6ioKNO7d2/7t4SEBAPAJCQkONcDwIwfPz7JcbPSfU8t2H/BZ8KECQaAWb16tWebokWLmmrVqhljvO9xqO/Ujz76yAAw69at8zxfnz59TKFChVL6lbIVHIMpI8XS0rhx45A3b1506dIFABAZGYnOnTtj+fLl+Pnnn5O0j4uLc1ZUatasCQDYuXOnnlihd+/eGDhwICZPnoynn376ktcyZ84cFCpUCO3bt8f58+ftf7Vq1UKxYsVC9sK+5557nO2uXbsCABISEgDAOmD16NHDade5c2dERERg0aJFTnvdrn79+qhWrZptlx0wxjh9cv78eQBAVFQUKlasiFdeeQWvvvoqvvvuO1y8eDHZY9SqVQtlypSx23ny5EHlypWTPDtedOzY8cq/SDaF/Zf1MMYk+Zu+x6G+U2vVqoVcuXKhV69emDRpErZt25bk2PXr18fRo0dx9913Y/bs2Th48GCafK+sCsfgpUnRRGbr1q1YtmwZ4uLiYIzB0aNHcfToUXTq1AkAkmhvABAdHe1sJ0owp0+fdv5+9uxZTJ06Fddeey3atm0b0vXs27cPR48eRa5cuRAeHu78t3fv3pAGTs6cOZNcY7FixQAAhw4dsv/PmTMnYmNjnXZhYWEoVqyY0w4AihcvnuQ8JUqUsPuzA5MmTUrSJ8Bf92zRokVo3bo1hg0bhjp16iA2NhZ9+/bF8ePHnWPofgH+en70s5Mc+fLlQ4ECBVLny2RD2H9Zi5MnT+LQoUMoUaKE/Vty9zjUd2rFihWxcOFCFClSBI888ggqVqyIihUr4vXXX7fHuu+++zB+/Hjs3LkTHTt2RJEiRdCgQQMsWLAgfb50wOEYvDQp8pEZP348jDH46KOP8NFHHyXZP2nSJAwaNMjTp8WP3LlzIyEhAa1bt0arVq0wd+5cFC5c2PczMTExiI6Oxty5c5Pdnz9//kue9/z58zh06JDT4Xv37gXwfw9BdHQ0zp8/jwMHDjiTGWMM9u7di3r16jnt9+zZg1KlSjnn2b17N2JiYi55PVmF9u3bY/Xq1cnuK1u2rHUY37JlC6ZNm4bnn38eZ8+exZgxY1Ll/HQCvTLYf1mLzz77DBcuXHDycCV3jy/nndq0aVM0bdoUFy5cwJo1azBq1Cg8/vjjKFq0qF2xv//++3H//ffj5MmTWLZsGQYOHIj4+Hhs2bIFZcuWTd0vmcXgGLw0lz2RuXDhAiZNmoSKFSti7NixSfbPmTMHI0aMwBdffBFSEp7kqF27NpYuXYpWrVqhefPmWLBgAYoUKeLZPj4+Hh9++CEuXLhwReHfH3zwAfr27Wu3J0+eDAB20Lds2RLDhg3D+++/jyeeeMK2mzFjBk6ePGm9/W+66SYAwPvvv28nNwCwevVqbN68Gf/617/s30KdFQeV6OjoZP81oKlcuTL+/e9/Y8aMGVi7dm2aX1dWv++pBfsv6/Drr7/iqaeeQsGCBdG7d2/ftil5p+bIkQMNGjRA1apV8cEHH2Dt2rV2IpNIREQE2rZti7Nnz+L222/Hpk2bOJG5BByDl+ayJzJffPEFdu/ejaFDhyabXbd69ep48803MW7cuBRPZACgWrVqWL58OVq1aoUbb7wRCxcuTLK6kUiXLl3wwQcfoF27dnjsscdQv359hIeHY9euXUhISMBtt92GDh06+J4vV65cGDFiBE6cOIF69erZqKW2bduiSZMmAICbb74ZrVu3xjPPPINjx46hcePGNmqpdu3auO+++wAAVapUQa9evTBq1ChcddVVaNu2rY1aKl26tDMJqlGjBmbOnInRo0fj+uuvx1VXXeXkf8iqbNiwAX369EHnzp1RqVIl5MqVC4sXL8aGDRvQr1+/ND9/dr3vqQX7L3OzceNG60+xf/9+LF++HBMmTECOHDnw8ccfJ5HHNaG+U8eMGYPFixcjLi4OZcqUwZkzZ6xrQWLSvZ49eyJv3rxo3Lgxihcvjr1792LIkCEoWLCg8w89cnlwDP4flz2RGTduHHLlyoX7778/2f0xMTHo0KEDPvroI+zbt++KLq5ChQp2MtO0aVMsWrQIFSpUSNIuR44c+OSTT/D666/jvffew5AhQ5AzZ06UKlUKzZo1Q40aNS55rvDwcMyZMwd9+/bFoEGDkDdvXvTs2ROvvPKKbRMWFoZZs2bh+eefx4QJEzB48GDExMTgvvvuw3/+8x/r9wP8lTehYsWKGDduHP773/+iYMGCaNOmDYYMGeLMrh977DFs2rQJzz33HP744w8YY5J1xstqFCtWDBUrVsRbb72F3377DWFhYahQoQJGjBiBRx99NM3Pn13ve2rB/svcJL6fc+XKhUKFCqFatWp45pln8NBDD11yEgOE/k6tVasW5s+fj4EDB2Lv3r2IjIxE9erV8cknn+CWW24B8Jf0NHHiREybNg1HjhxBTEwMmjRpgnfffTekayHJwzH4f4QZjn5CCCGEBBRWvyaEEEJIYOFEhhBCCCGBhRMZQgghhAQWTmQIIYQQElg4kSGEEEJIYOFEhhBCCCGBhRMZQgghhASWFNVaItkTmXIopfU3Nm/ebO0+ffpY+84773Ta1a5d29q5cuWyds6c7iO7adMma3/88cfW1okTZRX1QoUKXeZVZ1/279/vbE+cONHa3bp1s3ZigdUrYd26ddb+8ccfnX2y+m5i0Tzizfbt2629dOlSZ9/s2bOtHRUVZe3EzOSJ1KlTx9qyP2bMmOG0W7hwobUjIiKsfe+99zrtevXqFdK1k4xj9+7d1paFRTM7XJEhhBBCSGBhZl/ikJJVl++++87Znjp1qrX1v95kRfQTJ05YWxcfO3z4cEjnllSuXNnaV13lztHlvyjl6kHr1q2ddk8++aS1QyltkRWR/fLhhx86+1577TVry5UynWpe7pMrKPLYAPDnn39a+7fffrP27bff7rRr2LChtTt37ux3+dmGL774wtojR4509uXNm9faZ8+edfblyZPH2seOHbO2XN0E4JSYKVeunLX1qmjx4sWtXbBgQWvLvgWAXbt2WTuxDhMAvPHGGyAuiYWHAeDIkSPOvpiYGGu/88471pZ95IdcdQGAFi1aWFu+h8uUKeO0mzdvnrXlyltmgCsyhBBCCAksnMgQQgghJLBwIkMIIYSQwEIfGRIyUk+XESvr16932slHKjIy0tkntXuptUvfGQA4f/68tf/44w9r58uXz2knPxeqT8+ZM2esrX1zpD9BkyZNnH3vv/9+SMfPSkyfPt3Zlv03ePBga2vdXfpXSF8JHTGWP39+a0u/ia5duzrtpG+N9p/JTvzyyy/Wfv75561dpEgRp518ri9evOjsk/5jcgxKHyWNHFt6rBYoUMDa0h9K+9JER0dbW/rL6GdixIgRnteRXWjevLm1ZZ8D7niS/azftZ06dbK2fHdduHDBaSd9pmRfyLEOJH3PZya4IkMIIYSQwMKJDCGEEEICS5ZJiKcVMi+Z4fjx4872l19+ae22bduGdHy5NKeXT0PFT9FLabK5tKZDhw7W/vXXX61dtGhRp528fr2MqZelvdrJ+yOXpHU7r8/4IZdM5bIq4F778uXLnX0ymV+1atVCOlfQ0SG0cun5kUcesfaoUaOcdrlz5072GFpGuP766619//33W3vHjh1OOx3enV2RsovfPZFykpRSAXcMyvdX+fLlnXYylFoeQ7+f9DOS3LEB4Ny5c9aWocIbN2502s2ZM8fa8fHxyR47qyMTFcrkhoD7PpRpKvbu3eu0k2NSykIbNmxw2hUuXNjaso/keTI7XJEhhBBCSGDhRIYQQgghgSXLSEvaM18un27dutXaY8eOddpJmUFmK9SSQ/369a3tJydJeUNfk9zndwwpn3hJMenBt99+62xLOUlml5QRRhodFfT7778nu0/fK3l/5P3QGXslMuJI1+OR0TGlSpVK9jwafS757GSXyAp53wDg4MGD1i5btqy19f2Q/XzgwAFr6+yj8jmSx9bPFIMr/6JHjx7Wltl8tcwk5V4tp3vVqpLZmAG33yQySglIGknohTz+0aNHrS3HI5B95SRJxYoVrf311187++RvgpRw/ZDjTkvmsqaSfCefOnUqpGNnBrgiQwghhJDAwokMIYQQQgILJzKEEEIICSxZxkfGL8x38eLF1l6wYIHTrnTp0taWYYRaH5w/f761e/bsaW2/0GM//xaZqVT7YoSqOac1CQkJzra8PzIcU1+/9HfRGu6wYcOsLavmyn4A3Eyxsp32pZF6v/SR0VWW165da21ZbVf7FsjwQ/29ZCXv7OIj4/cMHzp0yHOf9H2R1cb1uJK+NH5ZmjNrSoL0RvrqyYrgs2fPdto1aNDA2trfSPaBDPPVPjJybEifQd2HcszIkO39+/d7fAvXF+Pll1/2bJddkekd9DtPjgXp16n7T4dZJ6L9P6X/mexL7QuVmeGKDCGEEEICCycyhBBCCAksWUZa0stqktWrV1tbZwyVy3bSvuWWW5x23333nbWffvppa9etW9dpV6NGDWvr7K/ffPNNstfUqFEjp51cMpZLtenNRx995GzLpX95r3QIs1x61tcvZTkp1+lQ7wceeMDab7/9trWvvfZap52UuKS8qIvoPfHEE9Z+6623rC2XUvXx5LItAPz444/W3rJli7UrV66MrIpfxmz5PGhpV4bXpuRcWkryC/HPrvTt29far732mrNPhsZr+VQ+11LG9pMS5P3Xx5P7/KQJWfxVZlEPkoSRXviliJBjTcrpUoIHgNq1a1tb3mMd7q6lq0Qy8rfncuGKDCGEEEICCycyhBBCCAksgZaW/JaiZXTSmjVrrK2XMU+ePGltKRdIGwDq1atn7auvvtraOjpmxYoV1p45c6azTy4RyuiDd955x2knZbKbbroJGYUsNAa4kUVyedOraBzgLidrWrdube3IyEhnnyzQOHz4cGvLwpUA8Omnn1pbLnHLZVXAjVqS/aAjMGSkko5akt9/5cqV1s7K0pJ+vmVfy+gHLS3Jeyf3+WXo9ZJ5gaSFD7Mr8hmXz/FXX33ltPvXv/7leQwpJ8moP52FW2Y9l32o28nIRC+ZQu9r3769ZzviykQ6E7McQ1Le1e2kDC8lP91HUkKS49uvLzMbXJEhhBBCSGDhRIYQQgghgYUTGUIIIYQElkzvI5PSqrf9+/e39p49ezzbSR8Jv6qiX375pbWlz432zalTp461K1Wq5OyTx3/zzTetvW3bNqedzCCb3nz//ffW1mGWXuG22j9Caugyc6hm06ZN1tb3W/aZ1Pv18yB1YblP+rBopP4sMwgD/tllpc/AsmXLrN29e3fPcwUdvyrUoVZ6T0lFeN1OP2PZFa9q7Tr0tkKFCtbevn27s0/6Nsnq5tonTLaT/aH92WSVbL8+LFOmTLLXTpIi3706ZUjVqlWtLftIvxt1aolE/Hxu5DPgl9Iks8EVGUIIIYQEFk5kCCGEEBJYMr20lNJicYULF7a2lCmkPAC44WZyKU6HncolPCmd6OuTEpQMxQbcJbx9+/ZZu02bNh7fIv0ZOnSotXWYpcwI6hfCLO+VXsaUspwsOnj48GGnnewLea/08eS5ZJZLnVl26tSp1j5y5Ii19fMgP6f3yWvSmYizKloekKG7Uu7xk4z8Ck96jW8tNZLLQ95//S6T8oF8/0mZCXDHkxxnfpKDX1/rbNvEG1loVeNV5NEvXFqOMy0Xy205puVvaGaHKzKEEEIICSycyBBCCCEksHAiQwghhJDAkul9ZFKK9Nvw0/KlH4TUJaOjo512MgROasw65M0vlbf8nNSSd+3alfyXyABkJW7pmwIAW7dutbYsPaB9ZGTYuQ7pbNCggbXlPdDt5LbsMx1S6BW+q8N1ZWkKWVJAlqjQ59J9W6JECWvffvvtyA746e7yHuv+8xtzXkitXvvI6GeRuPdV3/+SJUtae8OGDZ6fk/dZH0OWhZD7dLkI+Q6VvjQHDx502umqy4lonw2vEPPsirynl4P0i/GqWg+491u+84JUlZwrMoQQQggJLJzIEEIIISSwZPo1PL28L5dF5RKZDjGUGVvl8qkOHZQhhrKdDDUGXClFyk5aVpHH0xkwjx07Zu0aNWpYW8sbMkS5bt26SE8efvjhZG3ADVv++eefrT169Gin3ZIlS6ytM/vK712oUCFry/sGpKzyql8GWbk8K/uyZs2aTrvJkydf9nmzGrKftUTnVXE+pZVypWQhJQa9nC7HmZQ2UrrsntUpV66ctXUfyrEm+7ps2bJOOyk5yFQJOixXtpPvV/3upmSUMkJNQaLbeY1V3U6OXblP/wZmZrgiQwghhJDAwokMIYQQQgJLpl/r08tgcplUSksycyvgZvOVBbh0JJE8hpR4fv31V6edzCgrs2Hq5VIZVaPPJb34H3nkEWuvW7fOaae9+DMLckm5fv361tYRJosXL7a27j957+T91t9ZR1AkopervQqeyfMAbv9JaUJGaZG/kP2p+zaly9yJ+EnFEi2HFCxY0NqUky6NzMDsl23XKzoQ8I5a0tKSLBqpJX6Jlo9JaIRaOFm3k+9Uv4hO2bfS3r9//2VdZ0bCFRlCCCGEBBZOZAghhBASWDiRIYQQQkhgyfQ+Mtp3wqvyavXq1Z1tqe1LvxWtD0r9WGqCWoeXYcTymnSmWen3obXk0qVLW1uG+f7zn/902t1www3IDGjNVX5X2Q/aH0JW0fW7337+Fl6hgynFyxdDhoBr/LTk1LimzIr8bvoepNd5tY8TSYqXHxng+kRIH0HAHbt+FY7l2JCf0b5/RYsWtbb0lwlS+G5mJqU+Ml5h1X6+NNKXUGazz+xwRYYQQgghgYUTGUIIIYQEllSRluRSlV+xONlOLmGFukTqR9u2bZ1tmVVXFjXzCwGUS7Ba0pKhiF7yFuBer18hPVnITYaWZia0fCL7TFKxYkVnWxYbC1UaDDUrZaj4ZXCW+N17/fz6hbFmJfzkJL9w3dT8jN+99yuWmJ3wuw8yi7jM3gu470OZsVcj34cys7LMjA14j2ndhzqlRSLM+OuPn7TkV+TW6xihpjShtEQIIYQQkg5wIkMIIYSQwJKiNT2/SJTUXiZctmyZsz1jxgxrf/nll9aWmSwBt7CjjIDQy2ryeuUx9HeUx5Aykz6en6e+lDdku5kzZzrt2rdv73mMjMSrYKdcqgbciDF5rwBXnpJRUHpZ1MvLPtTMsH5FB+UxsotcdDn4Pd9e/aLvo+yXUCOf/Ja/5bYcR9k5y6+frCZloWuvvdbZV6ZMGWvLcaHv5b59+6wt5SNdXFJ+TkpaxYsXd9r9/vvvntdLXLZs2WJtLYuHWqzV773p1U7+HspM9JkdrsgQQgghJLBwIkMIIYSQwMKJDCGEEEICS4ocWkL1Kzh8+LCzvXv3bmtLDVD+HXB9RmQ7wPW/kPqg9k2RYYUlSpSwttaBpZ+G1IR11V+pJcuKycePH3faLV++3Npaw5ahvtJX5Ouvv0YQ8AqD1t/TLwOuX4ZJr3apoQPLa5I+G35+Blk5e68ffvc01LD4ULORpuTzoYZwZ2fke0inR5A+LvJ9KDNyA+677ejRo9bW/ojSf0a/yyXy/SqzqBcpUsRpx/B6YPPmzdYuVaqUs0/eb/m7pJHvOb/xJNvJ3729e/c67VasWGFt+RuYGcieTwkhhBBCsgScyBBCCCEksKRIWlq5cqWzPWDAAGvLomFyORLwzvCpC/dJ6Uovd8qlL7lcpkOA5dLX1KlTrV2vXj2nnQwXlMusflkNZVbeEydOOPvkMqCWu+QyoCwuGaQMiqEgl5d133qF4vpJGClBf15KeXKfzjxMUqdQZKgSopdUpftFXlN27jMv2eW3335z2v3www/WrlChgrNPZvqVEvzVV1/ttJPvqG3btllbF5qU71A/ZLZ1WTT38ccfd9plVzlJsmjRImtrCVc+A34yXKgysFdxSf08jB492tqUlgghhBBCUglOZAghhBASWEKWluTS7mOPPebsk1KCX9FEr6y3Mmsu4MpEWjKSyOJlO3fudPb169cv2WPI5THAzT4ppaWbbrrJaSc9/3/++Wdr66JrUsLQS+ByCU/eJ+21n1kJNYrHL6pNZqmUz4eftOS3ROq1T2fDlJKkn4QhYdRS0r70koz8Ion87mNKotPkuJcFSrMDXrLLvHnznO1rrrnG2jq7trxn8r1ZsmRJp92PP/5obfkc6CgaKbUXLVrU2vrdKCUpmeVXvk8BoFKlSsjuyEhWnS1fvrNCjUbyQ447+azoyF0ZtZTZ4IoMIYQQQgILJzKEEEIICSycyBBCCCEksITsIzNp0iRra38UGd4nQ/Z01lutmSai/RSkBq71WKnjnj592tpSmwWA7t27W3vWrFnW1pWlt2/fnuy1f/vtt067hIQEa3tlQgRcfx/tpyGRuqduJ0MpS5cu7XmMzIpX9mXA1dr9Qge9/FikD5JuJ/vFr8q5RKcIIG62a91/Xpq8X/XylKD7Sx5P+3wQ108FAGrWrGlt3YfyfaP9EyVe/mN+Y1X6GeqQcOmb4+WnA9BHBnBTcuhw91DDqv3eh17IZ0X+vgJupl/53OjfwIyAKzKEEEIICSycyBBCCCEksIQsLckQYS33SAlJLjOVKVPGs51cvtaZIaOioqwtC5zpY8hlTF0MUkoYHTp0sHaNGjWcdnIJT0pferlMZqiV8oYOT5UFvbRk5BVurJflZaHMIEpLoRYVTckSqZdEpI/hJ3XI/tPLp16fyU74hXemZLk6VPz61iszc3ZGyuIyjQTgym8yoy7g9q8cq35jwS+thpc8pYtLSmlCugjIbPDZFZltGXDviU7PIe+3V7Z8wB2foaa6kMe+5ZZbnHbTpk2ztnS9yAxZfrkiQwghhJDAwokMIYQQQgJLyNKSlJP00qKUP2Tkj14ylPJMbGxssjbgLn3qZUu5Ty6f6uKNcgk8Ojra2rKYGuAuu0opTHuKy3PJ69XL4XIJXO+TS7dymbVgwYJOu3Xr1lm7ZcuWCBqhZpQMVZoIVUrwyxIr98nldFnIk/yFX7Sd13K1X1belKCfDTmu5DsmOyOjgvQ7Wb4ndX/Kd5l8R0m5XyOlD/1e8yroWb58eaedzOArPyOjVAHg8OHD1pZuBlmZ7777znOf3++I3xiU/SyfAb9s3XKc/fTTT0472WebN2+2NqUlQgghhJArgBMZQgghhAQWTmQIIYQQElhC9pGpVauWtWU4MwBMmDDB2iVKlLC2rBgNuCHS0qdFa7hSA9S6rdRg5fF0Fkqp+8kwQB2mKDVGqR3q40n/Hq9wc91O2oAbmi21SBlGCSTNUpxZSEm4bUp9J7z8Yvz8b/zCr70qj4fqz5OdkOPRL0NyaodByz7SOr4cL7/88ou1a9eunarXECTkO0qPM/nO035g8p0q30n6nst3o3znaZ8N+Q6UVa3r1q3rtFu2bJm15XtYv2ulP0528ZGZM2eOsx0TE2Ntnc1c9pPsI+0nKsenvMe6ncyyLPtW+nHq837//ffJfIuMgysyhBBCCAksnMgQQgghJLCELC1JnnvuOWdbyk7Dhw+3tpZMZNiylF10Bki5TKrDr71C/fwyufqFIkoZy+94ErlPX7tcgpVhhIC7DCiX7WSBNwC49957Pc+dkYSaiVcuV/tlC5Xo8FEvmUEvoevPeV2fvHZ5vFClquzE7t27PffJ++8Vig2EngHYq3CoHn9yyVsuu2dnZCZy/V6T79qNGzc6++SYlKkf9DHkPfdzBZASvyxeGRcX57ST73x5DJ3V1qtYZVZGyqWA+zuiJR6v1CK63aeffmrt+Ph4a+fNm9dpJ6VHnQXaq92mTZs822UEXJEhhBBCSGDhRIYQQgghgYUTGUIIIYQElpB9ZLy0bABo165dsvbixYuddtK3Rlad1imqpT6ufRhk6KBfKKisGCo1el25W+q7Uh8MNSxX+oMArs+M9ue4+eabrV2tWjVrZ4YUz2mFvgfSP0X2mW4nt/2ePS9fJu2X4RUGzvDrpMgxodMfyPsq753uh1D9kGRoqWyn+1n6aMhSItkZWQJGP9/Sd+Lo0aPOPnmfZboM7fsiy7RERER4nssL7W8hjyefI3lsANizZ4+1q1SpEtK5go70YQGAJUuWWFuPLTk2/EqsePm7+JXV8Wsn3ws1atTwPG9GwBUZQgghhAQWTmQIIYQQElhClpa8wlz9uOmmm5ztr7/+Otl2P/74o7Mtl0x1Fepdu3ZZu2zZstbWEo/OKkyunFDDkeVytax4C7jLlfKZ0s+XXOaW+/Q1yO1QK/lKGH6dlPr161t7y5Ytzj4pU8ilZo1cDpf9Euo9lfIC4D4D2UVuuBSyCrhOA6FDmiWyKrJ8b+qwZ/keluHcuvq4bCdtHVLsFV6vnwkZepxd6Nmzp7Pdq1cva2tpScqGOhuzxOs3W6cvkGNaPg/Hjh1z2sntxx57zPO8GQFXZAghhBASWDiRIYQQQkhgSVFm39SmatWqvtuS6tWrp/XlkCtELlXqAmVS8pGZSbXEIyMjQpWJ/IpBymg1mdlUL397XQOQMnk1iEiZolu3bs6+hIQEax88eNDaWm6QMoVXVATg9pPsv3LlyjntpEytZZTsipRty5cv7+yT8pFGPtcy6kVLhTKacvLkydbWElTLli2TPbYeP/K9IPuwQoUKTrsWLVp4Xnt2QWZI1pnfJbposWT//v3J/l1nAJbPihyPWuKbN2+etaVbR2Yge7yZCSGEEJIl4USGEEIIIYGFExlCCCGEBJYw41fmmRBBqNWv//nPf1pbVy+XFXD9fF+kvi4zVPpVtfYK7QZcPw2p1ctQYyBphs3sSKj9LNGV3qUOLzN36+MVK1YsWTvU0O7sGiIPuL4qOgurXzZs6RcmfR1+++03p532uyGZg+XLl1t78+bN1taZ9EeOHGnt4sWLW1u+nwHXl+auu+6ytszSn9nhigwhhBBCAgsnMoQQQggJLJSWCCGEEBJYuCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwpMtEZuLEiQgLC7P/5cyZE6VKlcL999+P33///bKPFxYWhueff95uL1myBGFhYViyZEnqXTSxrFq1Ch06dECZMmWQO3duFC1aFA0bNsSTTz6Z0ZcGAChXrhzi4+Mz+jIyLRx/WZPMNC537NiBsLAwTJw48bI/m12fH/Zf6pGuKzITJkzAypUrsWDBAvTs2RNTpkxB06ZNcfLkyfS8DHIZfPbZZ2jUqBGOHTuGYcOGYf78+Xj99dfRuHFjTJ06NaMvj1wGHH9ZB47LYMP+S11ypufJqlevjrp16wIAWrRogQsXLuCll17CrFmzcM8996TnpaQrp0+fRp48eRAWFpbRl3LZDBs2DOXLl8e8efOQM+f/PS5dunTBsGHDMvDK0o9Tp04hX758GX0ZVwzHX/DGnxccl8GG/Ze6ZKiPzA033AAA2LlzJ5o3b47mzZsnadOjRw+UK1cuRcf/5JNP0LBhQ+TLlw/58+fHzTffjJUrV9r9s2bNQlhYGBYtWpTks6NHj0ZYWBg2bNhg/7ZmzRrceuutiIqKQp48eVC7dm1MmzbN+VziMv78+fPxwAMPIDY2Fvny5cOff/6Zou+Q0Rw6dAgxMTHOYEvkqqv+7/FJlHfmzp2LOnXqIG/evKhatSrGjx+f5HN79+5F7969UapUKeTKlQvly5fHCy+8gPPnzzvtXnjhBTRo0ABRUVEoUKAA6tSpg3HjxsEYc8nrfuutt5AzZ04MHDjQ/m3hwoVo2bIlChQogHz58qFx48ZJ+v75559HWFgY1q5di06dOqFw4cKoWLHiJc8XRDj+gkuo43Lq1Km45ZZbULx4ceTNmxfVqlVDv379kqzC9ejRA5GRkdi6dSvatWuHyMhIlC5dGk8++WSSe7d7927ceeedyJ8/PwoWLIi77roLe/fuTXIda9asQZcuXVCuXDnkzZsX5cqVw913342dO3em0l0ILuy/1CVDJzJbt24FAMTGxqb6sSdPnozbbrsNBQoUwJQpUzBu3DgcOXIEzZs3x5dffgkAiI+PR5EiRTBhwoQkn584cSLq1KmDmjVrAgASEhLQuHFjHD16FGPGjMHs2bNRq1Yt3HXXXcnqig888ADCw8Px3nvv4aOPPkJ4eHiqf8f0oGHDhli1ahX69u2LVatW4dy5c55t169fjyeffBJPPPEEZs+ejZo1a+LBBx/EsmXLbJu9e/eifv36mDdvHgYMGIAvvvgCDz74IIYMGYKePXs6x9uxYwd69+6NadOmYebMmbjjjjvw6KOP4qWXXvK8BmMMnnrqKTz++OMYO3YsXnjhBQDA+++/j1tuuQUFChTApEmTMG3aNERFRaF169bJ/pDecccduPrqqzF9+nSMGTPmcm9bIOD4Cy6hjsuff/4Z7dq1w7hx4zB37lw8/vjjmDZtGtq3b5+k7blz53DrrbeiZcuWmD17Nh544AGMHDkSQ4cOtW1Onz6NVq1aYf78+RgyZAimT5+OYsWK4a677kpyvB07dqBKlSp47bXXMG/ePAwdOhR79uxBvXr1cPDgwdS7GQGE/ZfKmHRgwoQJBoD5+uuvzblz58zx48fNnDlzTGxsrMmfP7/Zu3evadasmWnWrFmSz3bv3t2ULVvW+RsAM3DgQLudkJBgAJiEhARjjDEXLlwwJUqUMDVq1DAXLlyw7Y4fP26KFCliGjVqZP/2j3/8w+TNm9ccPXrU/u2HH34wAMyoUaPs36pWrWpq165tzp0751xLfHy8KV68uD1P4nft1q3b5d6mTMnBgwdNkyZNDAADwISHh5tGjRqZIUOGmOPHj9t2ZcuWNXny5DE7d+60fzt9+rSJiooyvXv3tn/r3bu3iYyMdNoZY8zw4cMNALNp06Zkr+PChQvm3Llz5sUXXzTR0dHm4sWLzrnj4uLMqVOnTMeOHU3BggXNwoUL7f6TJ0+aqKgo0759+yTHvO6660z9+vXt3wYOHGgAmAEDBlzmncq8cPxlPUIdl5KLFy+ac+fOmaVLlxoAZv369XZf9+7dDQAzbdo05zPt2rUzVapUsdujR482AMzs2bOddj179jQAzIQJEzyv+fz58+bEiRMmIiLCvP766/bv+vnJDrD/Upd0XZG54YYbEB4ejvz58yM+Ph7FihXDF198gaJFi6bqeX766Sfs3r0b9913n7NMFxkZiY4dO+Lrr7/GqVOnAPz1L7fTp087DlYTJkxA7ty50bVrVwB//cv1xx9/tH4E58+ft/+1a9cOe/bswU8//eRcQ8eOHVP1O2UU0dHRWL58OVavXo2XX34Zt912G7Zs2YJnn30WNWrUcGbmtWrVQpkyZex2njx5ULlyZWcpcs6cOWjRogVKlCjh3Me2bdsCAJYuXWrbLl68GK1atULBggWRI0cOhIeHY8CAATh06BD279/vXOehQ4dw00034ZtvvsGXX36Jli1b2n0rVqzA4cOH0b17d+ecFy9eRJs2bbB69eokS7VZpf8kHH9Zh1DH5bZt29C1a1cUK1bMjqFmzZoBADZv3uwcMywsLMm/9GvWrOmM34SEBOTPnx+33nqr0y6xryQnTpzAM888g6uvvho5c+ZEzpw5ERkZiZMnTyY5d3aD/Ze6pKuz77vvvotq1aohZ86cKFq0KIoXL54m5zl06BAAJHv8EiVK4OLFizhy5Ajy5cuHa6+9FvXq1cOECRPQq1cvXLhwAe+//z5uu+02REVFAQD27dsHAHjqqafw1FNPJXtOvdSWVt8to6hbt651FD137hyeeeYZjBw5EsOGDbPOadHR0Uk+lzt3bpw+fdpu79u3D59++qnnUn/iffzmm29wyy23oHnz5njnnXesP82sWbMwePBg55gAsGXLFhw5cgQ9e/ZE9erVnX2J/depUyfP73f48GFERETY7azWfwDHX1bEb1wOGDAATZs2RZ48eTBo0CBUrlwZ+fLlw2+//YY77rgjyRjKly8f8uTJ4/wtd+7cOHPmjN0+dOhQshPfYsWKJflb165dsWjRIvTv3x/16tVDgQIFEBYWhnbt2iU5d3aF/Zc6pOtEplq1arbTNHny5MEff/yR5O8p0eISf1D37NmTZN/u3btx1VVXoXDhwvZv999/Px5++GFs3rwZ27Ztw549e3D//ffb/TExMQCAZ599FnfccUey56xSpYqznZUiJDTh4eEYOHAgRo4ciY0bN17WZ2NiYlCzZk0MHjw42f0lSpQAAHz44YcIDw/HnDlznME5a9asZD/XsGFDdO7cGQ8++CCAv5xFE1cDEvtv1KhR1sFVowd3Vuw/jr+sjR6Xixcvxu7du7FkyRL7r3gAOHr0aIrPER0djW+++SbJ37Wz6B9//IE5c+Zg4MCB6Nevn/37n3/+icOHD6f4/FkZ9l/KSdeJjB/lypXD9OnT8eeffyJ37twA/po9rlixAgUKFLisY1WpUgUlS5bE5MmT8dRTT9mX2smTJzFjxgwbSZHI3XffjX/84x+YOHEitm3bhpIlS+KWW25xjlepUiWsX78e//nPf1Lh2waHPXv2JPuv28SlxcSJR6jEx8fj888/R8WKFZ0fM01i4rYcOXLYv50+fRrvvfee52e6d++OiIgIdO3aFSdPnsSkSZOQI0cONG7cGIUKFcIPP/yAPn36XNb1Zhc4/oJFKOMy8b4n9mcib7/9dorP26JFC0ybNg2ffPKJI09MnjzZaRcWFgZjTJJzjx07FhcuXEjx+bMK7L/UJdNMZO677z68/fbbuPfee9GzZ08cOnQIw4YNu+yXKPBX+NqwYcNwzz33ID4+Hr1798aff/6JV155BUePHsXLL7/stC9UqBA6dOiAiRMn4ujRo3jqqaccbR/46+Fp27YtWrdujR49eqBkyZI4fPgwNm/ejLVr12L69OlX9P0zK61bt0apUqXQvn17VK1aFRcvXsS6deswYsQIREZG4rHHHrus47344otYsGABGjVqhL59+6JKlSo4c+YMduzYgc8//xxjxoxBqVKlEBcXh1dffRVdu3ZFr169cOjQIQwfPjzJwNJ06tQJ+fLlQ6dOnXD69GlMmTIFkZGRGDVqFLp3747Dhw+jU6dOKFKkCA4cOID169fjwIEDGD169JXcpsDD8RcsQhmXJUqUQOHChfG3v/0NAwcORHh4OD744AOsX78+xeft1q0bRo4ciW7dumHw4MGoVKkSPv/8c8ybN89pV6BAAdx444145ZVXEBMTg3LlymHp0qUYN24cChUqdIXfPviw/1KZ9PAoTowkWL16tW+7SZMmmWrVqpk8efKYa665xkydOjVFUROJzJo1yzRo0MDkyZPHREREmJYtW5qvvvoq2XPPnz/fepBv2bIl2Tbr1683d955pylSpIgJDw83xYoVMzfddJMZM2bMZX/XoDB16lTTtWtXU6lSJRMZGWnCw8NNmTJlzH333Wd++OEH2y4xckiTXDTMgQMHTN++fU358uVNeHi4iYqKMtdff73517/+ZU6cOGHbjR8/3lSpUsXkzp3bVKhQwQwZMsSMGzfOADDbt2/3PXdCQoKJjIw0bdq0MadOnTLGGLN06VITFxdnoqKiTHh4uClZsqSJi4sz06dPt59LjFo6cODAldy2TAXHX9Yj1HG5YsUK07BhQ5MvXz4TGxtrHnroIbN27dokESrdu3c3ERERSc6TOB4ku3btMh07djSRkZEmf/78pmPHjmbFihVJjpnYrnDhwiZ//vymTZs2ZuPGjaZs2bKme/futl1miHpJb9h/qUuYMSFkFyOEEEIIyYSw+jUhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwpGlmX52iJiX1T3SV48WLF1v7nXfesbbONlitWjVry2ywR44ccdqtXLnS2rIOj06Fnjdv3pCuV37n7FjvhWRevFJGpfQ5lZXKK1as6OwrVapUSMfYvn27tdesWWPtzp07p+iaCCHZD67IEEIIISSwcCJDCCGEkMCS6iUKQpVWDh48aO3XX3/d2bdw4UJrnzlzxtkXERFh7bNnz1r7xx9/dNodP3482fOGh4c72yVLlrS2rEZ6+vRpp11UVJS1ZUn1Rx991GnnV9GZkIzk4sWL1tZFGSW7du2y9vjx4519I0aMsPaxY8dS8erca9LjdOjQodYOtVCp/L76+ISQrANHNiGEEEICCycyhBBCCAksnMgQQgghJLCkq4/ML7/8Yu34+HhrFytWzGmXJ08ea2utPEeOHNaWYdXShwUATpw4ccnPAK6fzYEDB6x9/vx5p92ff/5p7XPnzlk7X758TrvevXtb+4477gAhGUWoPiK1a9d2tn/++Wdry+cecJ93aWtfNukrJlMj7Nmzx2knfdFkigN9PDme5Vhv2bKl027y5MnwIlQfoeyK/inwul9+vo9+PycpCfNfsWKFs92oUSNr//TTT9auXLnyFZ8rq5Ha6RZC5d5777X2P/7xD2dfnTp1rC3fLfp3+XLhaCaEEEJIYOFEhhBCCCGBJdWlJT/uvPNOa8vwax2yLGUdvQwmpSa53KmXpuS2tKWUBAB//PGHtaVk5Hdb5JKrPp7cnj17trMvMjLS85iEpAahpj9o2LChtWVGXQAoWrSotfXzLY8px6mWak6ePJnsNekM2Tlz/l9ycTn+pLyskeeV7xEAuO2226w9a9Ysz2MwA3dS/KQlKc+nNkuWLHG2v//+e2tLmRMANmzYYG15vfPnz3faXalUkdGE+nympJ3G63NyPALub6/so06dOjnttmzZYm05HgF3TMp3S65cuTyvLxS4IkMIIYSQwMKJDCGEEEICS5pKSzpC4a677rJ2gQIFrK2XpeVy86lTp5x9Fy5cSNbWS59yWx5fR0PI4/tlFpXHkxKRPu+hQ4es/be//c3Z17VrVxCSUXz88cfWlhF1pUuXdtpJSUFKRIC7DC1tPQ7kWJKvGB1J5XVe3U6eS45NLUHJIrMzZ8509rVt29bz3FmZ1Cje68e7775rbVl4d/ny5U67N954w9olSpSw9vr16512MgJJRrkAQLdu3axdq1atlF1wwAhVFpK/hxo5nnRErpR7/SL7li1bZu0OHTpYW8tCMkpRZukH3Ez6qSnvckWGEEIIIYGFExlCCCGEBBZOZAghhBASWNLUR+aHH35wtm+//XZrS61MZw+Vfitae5chW146POBqfV4hoxrZTh9P+u1IYmJinG2ZqfSaa65x9ulKwoSkBn6+YhL5fMvnVo8JqXFrHxkZkuk3/uS5UpJF1y8rsZ9vjmTv3r3OtvTZk9nE9ff3GutBJTV8ZDZv3mxtfb9Gjhxpbek/ePjwYaed9Hdp1qxZsn8H3HQAOjWA/Jz0zbj66qv9vwC5bH777Tdnu1q1atbOnz+/tbVvzsSJE63drl07Z19apT3gigwhhBBCAgsnMoQQQggJLGm6hiqzMALukqRc9tXLyHJbh1fKsL2KFStau1y5ck47WdBOhpdFREQ47WQop5S4ZOZCAPj000+TPd7Ro0eddrK4nV6WJyQt8JJXdFZNKRlJCWDHjh2e7bQspNMSJOIX+pkS9Hm95CT97pDjXr87ZAbZLl26JHu8rEioS/g61YUs2CiluIIFCzrtHnjgAWtLmUm6DwBuAUEZJq+vr2rVqtZeu3ats2/BggXWlv2blaWlUIu/avbt22dtKfPJFCEA8O233yb7GS0hymKt8nmQ2fEBoG7duiFdX2rCFRlCCCGEBBZOZAghhBASWNJUWpLLtwDQtGlTa3/wwQfW3rhxo9Puueees7ZcZvRDL4vK6CFpa7lHZvqVspPOwjtkyBBr16tXz9o6MkIubW/bti2kayckLVi5cqXnPh0pKPFbuvbK7Ku50mBIfWyviEJ9rTKqSmfxXr16tbXluymrF43Usp9XBJiUxQG38KJ8R+sij2+//ba1586da+3WrVt7XlORIkU890nZScoZAPD7779bW0aBNm7c2GlXvXp1z+MHDb/+++WXX6z9+OOPO+2k24OMMtq0aZPTTrpryEjj5s2bO+28Io11gU6/yOBQCTUSMxGuyBBCCCEksHAiQwghhJDAwokMIYQQQgJLmvrIPP3008621PZatGhh7dq1azvtjh07Zm3tIyP1cVlBOzo62mknQ0hlyKjWw+XxZBiZ9tuR4X3Sv0eGserr0NphdiSllVu9dPyUZmH1q+oaKtL/Qp43s/pYyDQBgJsV2+++yT7T4dZe98Av/NovXNrr+fDTxeUzoEOspXavUy1MnjzZ2iNGjPA8flbDL5Rdop8X2TeLFy+29r333uu0GzNmzJVeooMMD5a/BQBw/fXXW1tm9tU+X/IY+rchaHilPADcFCQyoy5w5d87NjbW2ZY+Z9IH6a677nLaSZ8bv/e63BdqJn0vuCJDCCGEkMDCiQwhhBBCAkuaFo1ctGiR5/bBgwetPX/+fKdd9+7drS2LhAGu/LN161Zr69BBLzlCLo0D7vKkXPa69tprnXYyfG369OnW1vJR4cKFrT1z5kxnn8yUqcMKszupXbjvrbfecrYHDRpk7d27d1/RsTMz69evt3bDhg2dfTIjq1zW1Zk55ZK0lm7k8rJc8tbjSkpDfsVYvYrI+RWBleNUPycyM6kem3IM64J4JOXI9BbyeQk1PF+3mz17trW1NCGlFOlaIAuC6uvQRSmzC3LMyPvoJ1VJ7rzzTmd7xowZ1vYLrf/8889DvURPLlca5IoMIYQQQgILJzKEEEIICSycyBBCCCEksKRp+HW/fv3ckwk9W4ZoVatWzWn3ySefWPvFF1/0PL7U+rQe7qXRa03dy39GlzKQ4dwNGjSwtqwCCrhh5boiK/1ivLXxUH1iZAgtAKxbt87a0ndJ+3bIUMK7777b2lOmTAnpvIAbvjxs2DBr//vf/w75GGmNfJ51qLNE+pTp8FzZR9p3Se6Tx9c+LVKTl8f3C7/2C7n2aqd9KOQ7QX+vXbt2eR6fJCXUPpTIfSmtKn7gwAFr6/QWXs+f9pG8Uh+7IKLHoHy/+vnFyDEu71u3bt2cdvL9Ks8lfVUB12dKh/RLZDmERx55xNknyyG8//77nsdIhCsyhBBCCAksnMgQQgghJLCk6fpbhw4dnG0Zfv3tt99au23btk67W2+91dqyEioAlClTxtpy6VOHf8rlLb+so3IpTVau1ktxx48ft/bOnTutPXLkSKed3KerxMoMxjqbcVbCL7TSKyTz559/drblMqas4qxD9StUqGDtUqVKWVuG2gLAjh07rJ3S8MAPP/zQ2qtWrUrRMdKatWvXWltKYYB3eLNMQQC4y8FaYvVaotb96pWZWcs9cmz6ZXD2GsP673Lc68ykUqaQ/SelYvJ/eElD+u/yefF71/q9FyTymZs0aZKzLz4+3tpdu3a1tpag/CSNrEpKM4x7ZTqX9xpwU4vIytoyDB5wf+dLly7t7NNzgkSOHDnibGsXgkvBFRlCCCGEBBZOZAghhBASWNJUWtq8ebOzLaUbGe1zww03OO2++uora3///ffOPrl85uc9L9v5ZQyVeHnp6+uVS5q1atVy2pUvX97aelmtSpUqnufOLPgVV5RShZYjJH5LnHJJ8rnnnrP21KlTnXay4F/x4sWtXb9+faedlBRPnTplbV1s9Pfff7d2//79Pa9PSpn6mv7xj39Y+8cff7S2lEkBt7BdeiOfb/2sS0kg1Oye+hjyczLLr5YbvCSjUBOJ62dIFgWUGYp1tIqUpPR3lMd47bXXrH05kWuZFb+IlfTEL6LMq51GZnLVEvyaNWus3bt3b2v/8ssvTrtGjRpd+mKzAKHKdX7vhVCfFfl7Jl0tDh8+7LRr37695zGKFi1qbTk+ZbQv4L7zQ4ErMoQQQggJLJzIEEIIISSwcCJDCCGEkMCSpj4yWreUmqmsPquz4/qFQcswO6n16UyOXv4uWg+Ux5A+Fvq80ndCXp/W6KUvhvQHAYC9e/daW4YNZzR++qnEzy9GIsPvZMVUwA2rk5mOdbVx2Z+yOvOxY8ecdjLMUvrVSC0dcJ+xDz74wNqvvPKK5/Fq1Kjh7JM+FtI/RId6ZyQ6DFXiVQFX96t8Bvz8HCR+/mqh4hcSLseSHMM6xFxm4NbXJI8p+y8rkFE+MX6EmtlXZucGgOuuu87aMgs3AMyZM8fa8+bNs7Z+DrR/YlYlJf3uFW59KdavX2/tmjVrWltXHpdpKvT7esCAAdaWv50333xziq4pEa7IEEIIISSwcCJDCCGEkMCSptKSlilkIT8pHeileSnx6GUwuVwsl731ubzCiHU7r2JoeqlS7ouJiYEXMhRNZyfdvXu3tTOTtCSXJ0NdDn7jjTesPXr0aGffvn37rK2XeKtXr25t+QzIz/hdn580KPtSZ3XVS5yJ6DDNjz/+2PM6Bg0aZO3//ve/1i5btqzTThY504VD05r//Oc/1tbyqNyWMpkOn5Thr6GGS6cGcjxraUk+l/LadUZvKa3J9wjgSsKzZs2ydmYJXc4KyD70e5cMHTrU2vr5+9vf/mbt9957z9knn8127dpZW2buBkKXwbMyXqHZ+nfJq8CyHheyMLP8zb6cd8TgwYOtLX9TO3fuHPIxkoMrMoQQQggJLJzIEEIIISSwpKm0pKMGvGQAWYwKcAu/+UlLfkvAoWb29Vpu18tv8rwyO6GUywB3mU4fQ2ZDzEhkYUEAWLBggbV/+ukna+vIDimNye8iI0UAt3ijjDgC3Hus90mkDCDvo580KGUG/dzIaCTZZ7r4o8woqQsmlixZ0tqVK1e2tpYw3nnnHWvLJfT0YNu2bdaWS8GAe++ldKqlMfl90lNakviNU/nsaWnJL/O3lD3KlSuX7GfIlSHff1ruef75560tx3SRIkWcdjLSsVKlSs4+2d/yfRQUKUk+1/L59Btn+l2W0qgjr897Pf9169Z1tmX2XRkx5od20ZBjUL53/Nw1QoErMoQQQggJLJzIEEIIISSwcCJDCCGEkMCSpj4yGqmLSl1OZ/bVPgdeePnc6HNJLVLr5nI71Mqt0vfAL+zbL9twevPmm29ae+bMmc4+6ZPkl11V6tMyi66+BzJjo+4X6fsifWu0P5F8PqSvjj6X9PuQ915+J30MqdvKSsqA+wxo3y3ppyGPn9G+TzKbtLwurTt7Za7WfeRXBd4rpFOH2mpt3At5fHkMv9BP6Vuln1Hp/6T7RY7HX3/9NaTry2j0OyPU9AipfW7ZH7pv5ZjevHmztf/5z3867aRfmczsPmLECKedn8+SzAIs/cEaNmzo+Zm0wC9k368idUpSXaQ2fj42d9xxh7Vl9l4AmDBhQrKf0b+p8vj6vS79DnVl8yuBKzKEEEIICSycyBBCCCEksKSptBRqWKNewtfLURKvLL1axvEK0/a7JnkMvaQrzyWX73XosZQ6NBlZqO6+++6zdr169Zx9X331lbU3btxo7Z07dzrt5FL9kSNHrK1DYOV91MuOsvjmwYMHre0nb8ilbH0ur7BFXTxRSmFSjtDLu/L50KH18jrkcroOc46Li0v2mtKK5cuXJ/t3P7lHSkv6e8pMq1q68VoaDzUVQkqR91j2pX5upKyp3yPye6ZGkcv0wE9+8AvZTY177iW1y2cfcKXNV1991do33XST006mOpg+fXqKrkl+L79rSmv8Moyn5N7/+OOPzvb48eOtrSU6nbU8ET+JR/726PH+73//29oHDhywtnZB8MJPqvJLn1KxYkXPz13u/eSKDCGEEEICCycyhBBCCAks6Rq1FCpyGUwvrXplRvRbKvZbmvIqGqnlgqNHj1pbSks686T0qtfL8hmVJVWfWxZuBIAGDRok+xktk23fvt3aW7dutbbO4Ckzbmo5zav/9BKkLA4nC5TJvwOutCcjkLTkJ5ee/Zahpfzi118yIkhKHUD6Z4rVxSET0c+wVyZR+WwD7pK9n2TrNXb0trw+v3sqz6vvoZcUpr+7lDy1PKy/S9BJ7efMLxLHT+KSGXtLlChh7Q0bNjjtpk6deoVX6D5zUppOj8y+Utb2yzAunzMp2wDA2LFjra2jdSXyXTt79mxnn8y+7nUN+hrlmJERY4Ar833++eee1yR/92SmdD9JS45HwH2mmjRp4nkuSkuEEEIIyTZwIkMIIYSQwMKJDCGEEEICS5qKxtK3AXBDI/18WqQWpzVwqdX6hX15ZVrU2qZXqLeff4u89jJlyjjt1qxZY23to5CRmX2lz4iu6rxnzx5r+/kwREVFWbt58+bW1n4wXj4bgLcfhH4e5DG9QrEBV7eWn5HPGuCGFfpVT5bXrp8NmRlXPtva90JWda1RowbSmmbNmiX7d60te+n4+t7Le+DnZyOPr++V3JZ6ur7fXiG++njymvwyD8vjZ1Tm1NTEz29F+jbt27fPaSfHtByrfoTqczNw4EBnWz5L0i/m448/Dul4fuk2/LKjSx+Z9MDvvebF2rVrnW3ZT37vP1kRXKasAIBPP/3U2u3bt/c8t1d/3n333c52mzZtrO0XEi3Hcajs3bvX2Zb+hI0aNbrs43nBFRlCCCGEBBZOZAghhBASWFJdWpJL/37ZDwsUKOB5DLk87BcyKY/vt2Qdasinn2zltYxerlw5p528Dr9l74xEhwvrbS+k5Oe3hC9lHR3C7XUPtOzmVczT73Oyj7SsWbJkSWvL50Eva/t9L69nRd8/GYKaHnz22WfJ/l3Lo3JbSm1Fixb1bKfHjtfzre+VlKS85CjAvad+7WQ/+WXo9eqj5LaDgJ/c88MPP1hbh9TK96suwpuSLLgye++KFSucfVLS9coy7YefBOrXNr0Lfy5btszz3J06dbK2fD6lxKeR6SJ0dnsp4+j3y2OPPWZtP2lJctttt1l706ZNzj4d3p2ayAKvQOjP3uWmKuGKDCGEEEICCycyhBBCCAksqS4t+RVolMvScqlf45fh02vZUS9FeUUq6c97ZSfV55USl4x60Zl9/aSljMzsmxrI5U4/D3a9TErSlrlz5yb7dy3LSrlHPsOjR4922t1zzz3W1lKgLMYpn28tY8l9fuPZ6zM6Ek5uy+VqHbElC53q7M5e6IgfLbWlFikpLOgXtZSaUR+XomfPntbesmWLs2/OnDlXdGy/7O0a+YzoQotpzbZt26zdu3dvZ1///v2tLceIlOT0PhkFpaVB+Tm/wotPP/20tR966CGn3TPPPGPthIQEa7dq1cppp7OlpyZaWtOSvxeXm7WaKzKEEEIICSycyBBCCCEksHAiQwghhJDAkqaZfbXOJbU9vxDVUDN3eoVuJve5REKt8Oqn00qN/tprr3X2+VXkDrqPDMmcyBB3qUHrsFuvMdGhQwdnu2/fvtaePHmys0/61hw+fNjaxYsX97wmifaHkONP+gzozMzyc7JauwxFBYClS5cme+zkzp3IJ5984mxLf5DUJCXVqv0+I98n7dq1c/ZJH4t+/fo5+7p27RrSuV988UVrSz+sxx9/3GmXHtmrE5HvfF1ZOa3p0aOHtf/3v/85+2QovLwuPeZkxWv5jOsK9DExMdbW/mKy31955ZVkbQCIjY21tvRpfOGFF+CFV3X7lKK/V6h+a5d7bq7IEEIIISSwcCJDCCGEkMCSrtKSXBKThfU0MkxULo8B7tK5X6ZOr6J4fsUq5fXppXGvgoR+YeT6+vyKoxGSUuQ4k9JPqMu4mpdffjlZ2w+9/C2vwy/sWG7LEG6/zN+h4peVWGZflUX4gLSTlpYsWWJtHa4u32uyOKvO6irfjfI7SBsAtm7dau0RI0Y4+2T4rSxOOH/+fKfd66+/bm1ZeDLUZyKl+Mlp8v2tC5qmJzqj+9dff21tWUhYF7mVof7yu8iwbMD9/fG7HzLVhd/9kJKWnxSYEvlT/1ZKGUtn9vVKbaDfH/p5vhRckSGEEEJIYOFEhhBCCCGBhRMZQgghhASWVPeR8SoNoPFLVSw1N62dyRDNQ4cOWVunYw81lFoiNUut0Z88edLaMu2y1vLktWufGK2XEpIajBs3ztozZ860tnxmgdQPrZTocXC5GndqIX0XZIVvwPUZku+Vxo0bp/VlAQB27NiRrA0A+/fvt7b0L5LvO8D1iZDvuNKlSzvt7r33XmvXrFnT2bdw4UJry0rW33//vdOuSZMm1pZ+Ntq/R77z0tpvRfpftG7dOk3P5cezzz7rbE+ZMsXastyA/u2Rv3vyN0bfN+mron9HpK+XPL72/5TPkU6jILnS94Lf76v+/fbykfHzXQ0FrsgQQgghJLBwIkMIIYSQwJLq0pLMvKiXIEOVezp16mTtY8eOOftkOLY8l18otmznVyVbLqtpqapgwYLWrlu3rue55FKwviZ5HYSkFlIykdWfdXVkOZZCze7qh19aA79K8hKvfX5V6v3Cudu0aWPtsWPHOvtk2oS4uDhryyrBaYnMDBsqUj4HgF27dllbZlaWfwfceySfCcCVk+QzobMDy2dES1eS9AyDltLSq6++am1ZfTo90CHM8n7LLMgDBgxw2q1evdra+rcttWnatKm1W7RokWbn8ZOj5LMGeGf0T0nYt3MNV/RpQgghhJAMhBMZQgghhASWVJeWTp8+bW2/5WZdTEqiPcKDhFwi09/f7zsTkhr4ZRWVUQxaipDIaCedWVYil5RTOwrKDynRagm4Vq1anvuktNSnT5+0ubhUJjo62nc7uyGj0jJrH0p5U9qaLVu2WPvbb7919m3YsMHasgAo4EqK8vdGZ5kfM2ZMsufV7hVXOnb9pMWnn37a2a5SpUqy7bQbyuXCFRlCCCGEBBZOZAghhBASWDiRIYQQQkhgSXUfGVm5tXLlys4+GcLXoEEDz2P4hWZfaZhWWiNDFrdv3+7su/7669P7ckg2Q46dV155xdknx2bx4sU9j5GRVYVDwe8dINMzyFBdwP1e6enTQ9KGl156KaMv4YqQv4/6t/Luu+9Os/Om9m+o3/FkpXU//NKnhAJHMyGEEEICCycyhBBCCAksYSbUioqEEEIIIZkMrsgQQgghJLBwIkMIIYSQwMKJDCGEEEICCycyhBBCCAksnMgQQgghJLBwIkMIIYSQwMKJDCGEEEICCycyhBBCCAksnMgQQgghJLBwIkMIIYSQwMKJDCGEEEICCycyhBBCCAksnMgQQgghJLBwIkMIIYSQwMKJDCGEEEICCycyhBBCCAksGTqRCQsLC+m/JUuWpPgc5cqVQ3x8/CXbLVmy5LLONXnyZLz22mspvq7MwhtvvIGwsDBUr179io/Vo0cPREZGXrJd8+bN0bx58ys+3+WeNy0I8nOwatUqdOjQAWXKlEHu3LlRtGhRNGzYEE8++WS6X8uOHTsQFhaGiRMnXvZnL3fsZhXYf8EhM/VVcoT6O5lZydCJzMqVK53/2rVrh7x58yb5e506ddL8WurUqXNZ5wryD5hk/PjxAIBNmzZh1apVGXw1wSOoz8Fnn32GRo0a4dixYxg2bBjmz5+P119/HY0bN8bUqVMz+vLIJWD/BQf2VdqTMyNPfsMNNzjbsbGxuOqqq5L8PT0oUKBASOc9deoU8uXLlw5XlPasWbMG69evR1xcHD777DOMGzcODRo0yOjLIunAsGHDUL58ecybNw85c/7fa6BLly4YNmxYBl4ZCQX2X3BgX6X972agfWS2bduGLl26oESJEna5rmXLlli3bl2StnPnzkWdOnWQN29eVK1a1a5EJJLc8maiZPH999/jlltuQf78+dGyZUs0b94cn332GXbu3OlIYEFj3LhxAICXX34ZjRo1wocffohTp045bRKXjIcPH45XX30V5cuXR2RkJBo2bIivv/76kuf46quvEBMTg/j4eJw8edKz3dmzZzFo0CBUrVoVuXPnRmxsLO6//34cOHAg5O+zadMmtGzZEhEREYiNjUWfPn2SfJ8zZ87g2WefRfny5ZErVy6ULFkSjzzyCI4ePeq0u3jxIoYNG2avp0iRIujWrRt27dpl2wT5OTh06BBiYmKcF2siV131f6+FqVOn4pZbbkHx4sWRN29eVKtWDf369UvSl4ljZevWrWjXrh0iIyNRunRpPPnkk/jzzz+dtrt378add96J/Pnzo2DBgrjrrruwd+/eJNexZs0adOnSBeXKlUPevHlRrlw53H333di5c2cq3YXgwv4LDqH2VaK8c6nfKgDYu3cvevfujVKlSiFXrlwoX748XnjhBZw/f95p98ILL6BBgwaIiopCgQIFUKdOHYwbNw7GmEte91tvvYWcOXNi4MCB9m8LFy5Ey5YtUaBAAeTLlw+NGzfGokWLnM89//zzCAsLw9q1a9GpUycULlwYFStWvOT5rgiTiejevbuJiIgIuX2VKlXM1Vdfbd577z2zdOlSM2PGDPPkk0+ahIQE26Zs2bKmVKlS5pprrjHvvvuumTdvnuncubMBYJYuXWrbJSQkGADOZ7t3727Cw8NNuXLlzJAhQ8yiRYvMvHnzzKZNm0zjxo1NsWLFzMqVK+1/QeLUqVOmYMGCpl69esYYY8aOHWsAmIkTJzrttm/fbgCYcuXKmTZt2phZs2aZWbNmmRo1apjChQubo0eP2ra6/6ZOnWpy585t/v73v5vz58/bvzdr1sw0a9bMbl+4cMG0adPGREREmBdeeMEsWLDAjB071pQsWdJcc8015tSpU77fpXv37iZXrlymTJkyZvDgwWb+/Pnm+eefNzlz5jTx8fG23cWLF03r1q1Nzpw5Tf/+/c38+fPN8OHDTUREhKldu7Y5c+aMbdurVy8DwPTp08fMnTvXjBkzxsTGxprSpUubAwcOGGNMoJ+Dhx56yAAwjz76qPn666/N2bNnk2330ksvmZEjR5rPPvvMLFmyxIwZM8aUL1/etGjRwmmX2AfVqlUzw4cPNwsXLjQDBgwwYWFh5oUXXrDtTp06ZapVq2YKFixoRo0aZebNm2f69u1rypQpYwCYCRMm2LbTp083AwYMMB9//LFZunSp+fDDD02zZs1MbGys7QNjkh+7WR32X3AIta9C/a3as2ePKV26tClbtqx5++23zcKFC81LL71kcufObXr06OEcs0ePHmbcuHFmwYIFZsGCBeall14yefPmdfo08dxxcXHGmL/ek08++aQJDw93+vO9994zYWFh5vbbbzczZ840n376qYmPjzc5cuQwCxcutO0GDhxoAJiyZcuaZ555xixYsMDMmjXrSm+jL4GdyBw8eNAAMK+99ppvu7Jly5o8efKYnTt32r+dPn3aREVFmd69e9u/eU1kAJjx48cnOW5cXJwpW7ZsSNeaGXn33XcNADNmzBhjjDHHjx83kZGRpmnTpk67xIlMjRo1nMnIN998YwCYKVOm2L/J/nv55ZdNjhw5zNChQ5OcW09kpkyZYgCYGTNmOO1Wr15tAJi33nrL97sk9tPrr7/u/H3w4MEGgPnyyy+NMcbMnTvXADDDhg1z2k2dOtUAMP/73/+MMcZs3rzZADAPP/yw027VqlUGgHnuuefs34L6HBw8eNA0adLEADAATHh4uGnUqJEZMmSIOX78eLKfuXjxojl37pxZunSpAWDWr19v9yX2wbRp05zPtGvXzlSpUsVujx492gAws2fPdtr17NkzyQ+h5vz58+bEiRMmIiLC6eus/kOYHOy/4BBqX4X6W9W7d28TGRnptDPGmOHDhxsAZtOmTclex4ULF8y5c+fMiy++aKKjo83Fixedc8fFxZlTp06Zjh07moIFCzqTk5MnT5qoqCjTvn37JMe87rrrTP369e3fEicyAwYMuMw7lXIyvbRkjMH58+ed/wAgKioKFStWxCuvvIJXX30V3333HS5evJjsMWrVqoUyZcrY7Tx58qBy5cohL3F27Njxyr9IJmPcuHHImzcvunTpAgCIjIxE586dsXz5cvz8889J2sfFxSFHjhx2u2bNmgCQ5B4aY9C7d28MHDgQkydPxtNPP33Ja5kzZw4KFSqE9u3bO/1cq1YtFCtWLORohnvuucfZ7tq1KwAgISEBALB48WIAfy2jSzp37oyIiAi7RJrYXrerX78+qlWrlmQpNYhER0dj+fLlWL16NV5++WXcdttt2LJlC5599lnUqFEDBw8eBPCXfNu1a1cUK1YMOXLkQHh4OJo1awYA2Lx5s3PMsLAwtG/f3vlbzZo1nWckISEB+fPnx6233uq0S+wryYkTJ/DMM8/g6quvRs6cOZEzZ05ERkbi5MmTSc6d3WD/BYdQ+woI7bdqzpw5aNGiBUqUKOG8L9u2bQsAWLp0qW27ePFitGrVCgULFrT9P2DAABw6dAj79+93rvPQoUO46aab8M033+DLL79Ey5Yt7b4VK1bg8OHD6N69u3POixcvok2bNli9enUSuTI9fzcz/URm0qRJCA8Pd/4D/hp0ixYtQuvWrTFs2DDUqVMHsbGx6Nu3L44fP+4cIzo6Oslxc+fOjdOnT1/y/Pny5UOBAgVS58tkErZu3Yply5YhLi4OxhgcPXoUR48eRadOnQAgWU1W38PcuXMDQJJ7ePbsWUydOhXXXnutHViXYt++fTh69Chy5cqVpK/37t3rDHQvcubMmeQaixUrBuCvAZr4/5w5cyI2NtZpFxYWhmLFijntAKB48eJJzlOiRAm7PytQt25dPPPMM5g+fTp2796NJ554Ajt27MCwYcNw4sQJNG3aFKtWrcKgQYOwZMkSrF69GjNnzgSQtO/z5cuHPHnyOH/LnTs3zpw5Y7cPHTqEokWLJrmOxL6SdO3aFW+++SYeeughzJs3D9988w1Wr16N2NjYkMZudoD9Fxz8+iqRUH6r9u3bh08//TTJu/Laa68FAPu+/Oabb3DLLbcAAN555x189dVXWL16Nf71r38BSNr/W7ZswapVq9C2bdsk6Tj27dsHAOjUqVOS8w4dOhTGGBw+fNj5THLvz7QiQ6OWQqF9+/ZYvXp1svvKli1rHVa3bNmCadOm4fnnn8fZs2cxZsyYVDl/UJw3L4fx48fDGIOPPvoIH330UZL9kyZNwqBBg5wVmFDJnTs3EhIS0Lp1a7Rq1Qpz585F4cKFfT8TExOD6OhozJ07N9n9+fPnv+R5z58/j0OHDjkvgkQHxMS/RUdH4/z58zhw4IAzmTHGYO/evahXr57Tfs+ePShVqpRznt27dyMmJuaS1xNEwsPDMXDgQIwcORIbN27E4sWLsXv3bixZssT+Kx5AEsfoyyE6OhrffPNNkr9rZ9E//vgDc+bMwcCBA9GvXz/79z///DPJC5P8BfsvOOi+uhxiYmJQs2ZNDB48ONn9JUqUAAB8+OGHCA8Px5w5c5wJ6qxZs5L9XMOGDdG5c2c8+OCDAIDRo0dbZ+TEd96oUaM8o3v1BDc9fzsz/UQmOjo62VmqpnLlyvj3v/+NGTNmYO3atWl+XaGu6GQ2Lly4gEmTJqFixYoYO3Zskv1z5szBiBEj8MUXX6Q4QVLt2rWxdOlStGrVCs2bN8eCBQtQpEgRz/bx8fH48MMPceHChSsK//7ggw/Qt29fuz158mQAsMn3WrZsiWHDhuH999/HE088YdvNmDEDJ0+etEupN910EwDg/ffft5MbAFi9ejU2b95s/0UDBPc52LNnT7L/Ykpc8i9RooR9ESWuviXy9ttvp/i8LVq0wLRp0/DJJ5848kRiXyUSFhYGY0ySc48dOxYXLlxI8fmzCuy/4BBKX10O8fHx+Pzzz1GxYkXffySGhYUhZ86czj9IT58+jffee8/zM927d0dERAS6du2KkydPYtKkSciRIwcaN26MQoUK4YcffkCfPn0u63rTg0w/kfFiw4YN6NOnDzp37oxKlSohV65cWLx4MTZs2OD8CyCtqFGjBmbOnInRo0fj+uuvx1VXXYW6deum+XmvlC+++AK7d+/G0KFDk82uW716dbz55psYN27cFWV6rFatGpYvX45WrVrhxhtvxMKFC5OsbiTSpUsXfPDBB2jXrh0ee+wx1K9fH+Hh4di1axcSEhJw2223oUOHDr7ny5UrF0aMGIETJ06gXr16WLFiBQYNGoS2bduiSZMmAICbb74ZrVu3xjPPPINjx46hcePG2LBhAwYOHIjatWvjvvvuAwBUqVIFvXr1wqhRo3DVVVehbdu22LFjB/r374/SpUs7k6CgPgetW7dGqVKl0L59e1StWhUXL17EunXrMGLECERGRuKxxx5DiRIlULhwYfztb3/DwIEDER4ejg8++ADr169P8Xm7deuGkSNHolu3bhg8eDAqVaqEzz//HPPmzXPaFShQADfeeCNeeeUVxMTEoFy5cli6dCnGjRuHQoUKXeG3Dz7sv+AQSl9dDi+++CIWLFiARo0aoW/fvqhSpQrOnDmDHTt24PPPP8eYMWNQqlQpxMXF4dVXX0XXrl3Rq1cvHDp0CMOHD08yudR06tQJ+fLlQ6dOnXD69GlMmTIFkZGRGDVqFLp3747Dhw+jU6dOKFKkCA4cOID169fjwIEDGD169JXcpisj3dyKQ+Byopb27dtnevToYapWrWoiIiJMZGSkqVmzphk5cqQTXSPDyiQ6csYrasnreg4fPmw6depkChUqZMLCwkwmu5We3H777SZXrlxm//79nm26dOlicubMafbu3Wujll555ZUk7QCYgQMH2u3k7teuXbtM1apVTbly5cwvv/xijEl6740x5ty5c2b48OHmuuuuM3ny5DGRkZGmatWqpnfv3ubnn3/2/U6J592wYYNp3ry5yZs3r4mKijJ///vfzYkTJ5y2p0+fNs8884wpW7asCQ8PN8WLFzd///vfzZEjR5x2Fy5cMEOHDjWVK1c24eHhJiYmxtx7773mt99+c9oF9TmYOnWq6dq1q6lUqZKJjIw04eHhpkyZMua+++4zP/zwg223YsUK07BhQ5MvXz4TGxtrHnroIbN27dokESpeYyUxgkGya9cu07FjRxMZGWny589vOnbsaFasWJHkmIntChcubPLnz2/atGljNm7caMqWLWu6d+9u22X1qJfkYP8Fh1D7KtTfKmOMOXDggOnbt68pX768CQ8PN1FRUeb66683//rXv5x33vjx402VKlVM7ty5TYUKFcyQIUPMuHHjDACzfft233MnJCSYyMhI06ZNG5sCY+nSpSYuLs5ERUWZ8PBwU7JkSRMXF2emT59uP5f4zMgQ+7QmzJgQMuMQQgghhGRCMn3UEiGEEEKIF5zIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwZIqEeLrYVP/+/a29YsUKZ1+3bt2s/fDDD6fZNU2fPt3ZlllwZQ2hxx9/PM2ugfzFTz/9ZG1dxiAqKsraMg13o0aNnHYlS5a84uuQmQqyYukKQggJIlyRIYQQQkhg4USGEEIIIYElwzL7/u1vf7P20qVLnX0XL160tq6ouWnTJmvLCsalS5d22lWqVMnaBQsWtLauvCqlq7Nnz1r72LFjTjtZ9EtKYbp+0DvvvGPtChUqgHgTqlSTWMQRQJLKu+fPn7f2n3/+6XmMhx56yNqy1sypU6ecdjfeeKO1R4wY4ezLmzevtWXhu5RUCSeEEJI6cEWGEEIIIYGFExlCCCGEBBZOZAghhBASWNLVR2bx4sXWHjp0qLWjo6OddtI/RfrLAMCZM2esfeDAAWvrEO5ixYpZu27dutZevXq15/EKFSpkbe2bs3//fmsXLlzY2kePHnXaFShQwNoff/wxiDeyb6+6yntOfc0111j7+PHjzj7p15QrVy5r636RvjSyz8PDw512586ds/ajjz7q7HvjjTesffr0aWtL3xlCCCHpC1dkCCGEEBJYOJEhhBBCSGBJ18y+CxYssHa5cuWsrcNm5XK/XOoHgJiYGGvnzPl/l68VMhkeK0O2tQwQGRlp7fz581v7999/d9rly5cv2XPp8Gspi3355ZfOviZNmoD8H37SkpSMfv31V2tHREQ47aRkJOVF2a+AKwdu377d2lKOAty+feKJJzyv3U8KI4QQkn7wbUwIIYSQwMKJDCGEEEICS7pKS7t377a2jO7xk5akRKTbSllASwlSmpDoLKxSCpJZXqWUpI8vZQV9fTJDLaWlpEjpRkekSWSEm5SMpPzndwzd//IY8hnS0mXNmjWT/QwA7N2719oyKk5fA2UnQghJP/jGJYQQQkhg4USGEEIIIYGFExlCCCGEBJY09ZHRvgPSH0VWpJY24GZe1UifBumfcuLECaedDMuVvjTaJ0Jeo/yMvnb5uTx58nhen/SR2bJli2e77Iq8Pzr0WSIzMEt/FJl9GQB++umnZI+tfZxkFmiJ9NUCgNtuu83a8+fPd/Zdf/31yV5TBhWQJ4QQAq7IEEIIISTAcCJDCCGEkMCSptKSzKAKuHKNLLqnl/dlFlYtBcmigTKzrw63lcv9UqrSMoAM9ZbSkm4nZQsZXqslDInODkzc+yrvqSYhISHZv2tp6eabb7b2tm3bPI8tpaVatWpZe926dU47+Rx17NjR2Ve2bNlkr0mH9BNvduzY4Wzv2rXL2kxPQAhJCVyRIYQQQkhg4USGEEIIIYElTaWlPXv2ONu5c+e2tpRntIwjl/B15lyZ2VV+TkctSclInkv+HXClK1lQUssFMsKmePHi1tbZX+V1REdHO/ukvBEbG4vsiOxPKQ1qpEwkMy5//fXXTruoqChry+dBR8I1b97c2lLOuPvuu512//nPfzyvKVRZjLhMnz7d2v3793f2tWnTxtpSNqxevXqaXtP7779v7cqVKzv76tevn6bnJoSkLlyRIYQQQkhg4USGEEIIIYGFExlCCCGEBJY09ZE5dOiQsy19S/744w9rL1u2zGl3zz33WLtEiRLOPul3I6sYS/8WwDtrrPbLkO1k+LVuV6RIEWtLPw1d6bhatWrWlpmMAeDHH3+0dnb1kfEKVV6+fLmzvX//fmtLfwn9TB05csTaMmxfZ/KVmXi3bt1qbdlf5NLIFAry2depBvr27ZvsvgoVKjjtNmzYYO1evXpZe8WKFSFdj/aNGz9+vLUPHjzo7JMpH2Q1e/2OyWr4pZLw44033rB2nTp1rC3fhYD7PpTvNVlJHgBKliwZ0nlDZciQIda+9tprnX233nprqp6LZG64IkMIIYSQwMKJDCGEEEICS5pKS3p5X2bllZlbdbtvv/3W2jfeeKOzTy5Fy3BNLSXJJXAZcq0zAEs5SWYA1mHVMiRcZvNdtWqV004eo1SpUs6+9evXW7tp06bIjngta8twWMBdDpd9pEPapaTolaVZt5N07tzZ2f7HP/5h7VdffdXz2rNrKLZXgczDhw8727KYZ7ly5aztJ0vI94B+Hlq0aGHtOXPmWPvjjz922kn5SI+x7t27Wzutw7szEzqFhVfag4ULFzrbXbp0sbaUjPQ9l9mx5bvxrbfectpJWbFevXrWlsVYAVfu1ZmgFy1aZO2dO3daW/Y7QGnJDz2GZb/LPqpYsaLn5zLbO48rMoQQQggJLJzIEEIIISSwcCJDCCGEkMASZrxE7zRAappPPPGEtWWYH+CGUOqwTulnI6tma98XifSX0V9XhgPLVPj79u1z2slQU5lyXftRyOsdM2aMs0+WaMguaH3eK/y6fPnyzrYsHSFt2Ud6n1fIvT6+9LPSz8PkyZOtPXXqVGff7NmzPY8fNOSY0Hp3aujf0rftt99+s7ZfhWsZWr9y5Upnn/Q3u+6666wt/V4A1/dFpnvQePlgAUnLmAQB2Z9A0rQQks2bN1tbvstk6Q7ADVGXqQ30/cmTJ4+1pf+N9luRZUNkX+/du9dpJ/1xtD/PnXfeaW05Vrds2eK0e/fddxFkUsMfRZZ5efHFF60tfdYAYOnSpdZu3769taW/YFrw5ptvWrtWrVrOPr/3RHJwRYYQQgghgYUTGUIIIYQElnSVlkJl5syZ1h49erSzTy4xSylBSgwauXSsl2AlMnRw+/btzj4pkSxevNjzGMTFb8lbSjxSLgBcKUjKiRq5DC2XUnUWUSlDynDRMmXKOO2++uora5cuXdrZlwmHii+XIzekNjItQcuWLT2vQcoXsi+OHj3qtHv77bet3axZs9S6zEyPfubktrS9JFsAmDt3rrM9cuRIa/fp08faMts64Mo1Uk7SofZS+pDSb0REhNNOht5Lmf2XX35x2smwX50eQT4/zz//vLV3797ttJO/GzoNRkbi9Q65HPlI/tZt2rTJ2p988onTTmbBlzKffp9KGUdmSr/55puddilJGSJTqQDAww8/bO3vv//e2rfffrvTTsqGocAVGUIIIYQEFk5kCCGEEBJY0jSzr15Gk0vdXpl3AaBGjRrWlkvPgLsEJ4+hIw+kt7vfkrr8nDy2lJkAN/LCDx2lI/Fb/s2q+N37+fPnW1s/A3LpWS6l6n6WRQNlEVFdCFBmjZXn+vXXX512/fv397zeHj16WHvixIme7dKCUKMYZDu/ey8jRd577z1n3xdffGHtlMqoDRo0sLaMNJHHBtxxKsezzsQso2v8pCU5/rRUIp8VudSuZQkZoaOjKdIb/Q6VfSrvl8ykDABVqlSx9gsvvODsk1GhMoO5jhy89957L/t6pSQ4b948Z5+UdKUMrCUoKS3prO8ymlTKWPr9ISOwUkta8pL1AHdM+o3PlEQg6XfUc889Z235DGiZXEYnRUVFWTt//vxOOylJyWz5OoOzlItlhnV972VxZH3tjRs3trbM2rxx40ZcCVyRIYQQQkhg4USGEEIIIYGFExlCCCGEBJYMC7/20/xl2JgM1wKAokWLWltWmtb+AFIrl8fXPhYS6cOiw7mlpisr9moyc4XQ9ELee+0XJP1YKlWqZO1ixYo57aTmL7M26+y9Uu+VWZV1OJ/Ud6XOrn2wjh07Zm1Z8Vwjs1LGx8d7tkstQtXn/f7++OOPW/ubb76xtgxNB9z707BhQ2efrmgcCnIsTZkyxdm3ZMkSa0vNXIeISt39pptusrYOEZW+EbIvAXfsS98crfHL51KGJ6clob43ZL/JUFn5PALuPdLZj+V97tq1q7WlHxLg+ip63buUIn0i/vvf/zr7ZH/o97D0Z5LvBenXBAB9+/a19g033HBlF3sF6BQI0k/r4MGD1ta+JDLE/eeff3b2ST8kmbZC+iAB7riWfavvVatWrZK9dv2ulWNLPq86q770b9Tvf+nXJH+/dSZ9eb3ahyo5uCJDCCGEkMDCiQwhhBBCAkuahl/7IeUHvVQplxP1PrnsKJfpdLimXLaSn9FLfV5FzvSyWuXKlZP5FkmhtOQfZj5o0CBry5B2GfYHuFl1vWQmILRlR31N8hnQkqR8jqQMBrjF8T7//HNrawlDLtenFqGGd/px7bXXWvuDDz6wtpRSAODqq6+2tg7B7Nevn7V1uKcXcvzpDM5SqpL3W4ZpAkDt2rWtLSUPXQCvfv36yR5PI8e9LGAIuBloU5OUFOrUmc2lLCT7s3nz5k67BQsWeO778ssvrd2uXTtr+73j5PX5SZuhvv9koWAd/i5/G7TEKMeafGdoiVinX0ht9O+IV8ixzoIsUwJImUWHREspT9/va665xtrLli2ztgyJBlw3DPlM6/eVV3i6DM0H3LEr5S39Dpa/y7rIrwzxl0VEpWQKuLIbpSVCCCGEZGk4kSGEEEJIYMkwackPGX2iIwqkZCTRy2D6c4loKcFLxvIruOeXNTJohQVTg8spTigz4sqlYZ05WXrcSylh69atTjsZuSFlBrm8CXg/DxopL+rlXhkJkpLonStBSmp6uVYu0fot5/fs2dPaMnpISw8DBgywto74kNla5fF0/8nIPhnxp8dvzZo1rV2vXj1r6+VkKRPJaLI1a9Y47eR16MKTUq6Uz6wcz4Art6QmKSnaqd8vUmKT8oOWB6tXr25t/f3q1KmT7D4ZbaIJNSu53/Mnn5133nnH2m3atHHayWKVMTExzj6ZcV0+9/r60kJaev/9960tJVYAeOCBB6wtC9nqiEAp/8jvpqUxmdFYHg9w5SqZeVo/A/JdJqPv9G+UV3Z0naVevmsl+/fvd7alLKTfu/Jca9eutbaUTFMCV2QIIYQQElg4kSGEEEJIYOFEhhBCCCGBJcN8ZPy01JUrV1pba2zSV0Dq3FrflfqgX6ZB2U7q8joDsGwnNUGtYctrymrVrr1CK/20/08//dTZlpq89JGR9xdwQwRlCKYO35XPw86dO62t9V15Lnm9fllKK1So4GyPGzfOs21a88svv1hbVxWW/eJXQVrq8NJXRYdYy3Y6DUGvXr2sLbV6nYFVfq5q1arW1iHR0j9i9erV1i5ZsiS8kCGsTZs2dfZt2LDB2i1btnT2yWdPjm9ZKRpImS9LWqHDUr38FHRmVJkqQGeoluHO8rnyQ94vmXkdcPtD+jdqv0V53hkzZlhbh/HLzLPaV0r+HshnTPuNpUb2YU3btm09jy/7KdRKztIHT7//tm/f7nkuOYbk5/Qx5DtQ9p+uCi8/J599/dsrx7j0/dF9JN8ffr/z8ndZP7/ffvuttf0yrCeSeUYsIYQQQshlwokMIYQQQgJLpiwaKQtF6nBNuQwmZQUd5ialCbnEruUeGQ4m98kwP8BdJr3jjjusfffddzvtUru4WtCR4aKAGxIrwwV1+K7sd7/QPJmNVEpQevlb9oVc0tR9JJddZWgjAHz33XfJXkOoRRyvBHl/Nm3a5OyT90BmGPUrBiklCh22KZe1dQi6lO9kGK9f4ThZ9E4vE8vjSTlEL1fL48slbh36L8+rw46lLCk/pzPLSrlLFzO9EmRG3ZkzZzr7ihcvbm0pg8pQVsANy5VjRKcbkNv6eZTPq3zP3XvvvU47r3eZloy8pFotS8r3q/yMljrkONaSpdyW0ocOAX7wwQetnVqZmuVvih5bqY38nlrqlNKSvAf6PeSVqkT/BspjSDsjM9PLZ0C/g5KDKzKEEEIICSycyBBCCCEksKSr9uFVrE9HCMnlUx2N5Fe8TCKXov2kBHkMr8KCgLvkJosYajJTxENa4ld4UUafrFu3ztkns1TKdrpopCwuJosY6iJyMjuk9JZv0qSJ005mmpXPhl7+ls+XzBzqR3oswUp5VEaGAG70kFz+joqKctpJOUn2g5b1pKQmC+ABrpz0/fffW1tGmgDucrDMsqplHLn8LaUlHd0kt+Wzp7OeykgN3X979+61tl9RPi0rpxYy267uQ7kti1jKwn+AK0HJe6cLAUpJSt9LKTvJ7y4LugJupmwZFaTf1xJ5PH1f5fMi+0b3kxxPWlqSyOKJ+n5269bN83MpRcpJ+n7LbfkMahlH/v74tZPo94vsTzlm9DH0b1giul+8fkf13+XxpK2fL/l8+H0veQwtTUs5kNISIYQQQrI0nMgQQgghJLBwIkMIIYSQwJKuPjJeWpzWG2WFUB1WJ3VK6S+hsxDqzK6JaH1XXpP8jNYl5ed0BWaJ9BdJj7Dc1MZLBwXc7+bnC/TMM89YW2q4gHsP5D6tccuQa9lOZ2GVOrkML5ZhvYDrnyBDlLWGK31mtN9HRiKfe33v5T6/bNdSa5ZjTIfu/vDDD8keD3DHowzb1uPKy6dF+0LJrL/S10f6ggBun8nvpfV56W+hfYSkT4nMJiuPDSStRJxayO9+1113hfQZ/R6T30GGQes+lPdcv1/lMy59UPT7SaZKkMfTlaXl+JTPgc62K48n2/lVSNbjUz7r0pdJZ1jXfZ/a6PDrtA7HJv5wRYYQQgghgYUTGUIIIYQElkwhLenwT7kU6hd6JkO2dDu5ZOoV4qk/J7MG65Avr4yVOjxQLpPqZfnMUkRS94P8DvK7hRpK/sorrzjbMtS5WbNmzr4VK1ZYW94PHYIpl57l9emMvVp6TGTs2LGe1yRDwvWSsDyXDu3NSGS/6Hsl0wHIdrrAoMygKuUTvzBLjbw/UgrSGWjlOJUSsD62PJ5fqK2XtKafB/ku0WHUUpKS415ncM5MKRT0O0NmPJZ2amWvJSSIZJ4RSwghhBBymXAiQwghhJDAkimqGuqogVCzk/pJPFKa8JOW5DGkV732pJefk8fTBc9iYmKsnUH1OC+JluF0dttEdMSEzPI6atQoa48cOdJp17BhQ2vLbKoA0KhRI2vLrLw6Y6+XDOC37P/JJ59Yu3379s6+zz//PNnP6OPJPvPL7OtX9DStkUVLAVeukQUa9b2XMty2bdusrQs0yudbZ8KW90SOMZmJGXAjvqRMq6USGZ0kPxOqvKOfUfkd9RiWcpefrEkICRZckSGEEEJIYOFEhhBCCCGBhRMZQgghhASWTOEjI8M4AVfL1hq99EmR2Um1Vi79FqQPgc5AKsNQpY+MDr+Wx5Dn0n4I0kcmKHz00UfWvv/++62t75X0nZBoH4NNmzZZ+/rrr3f2bdiwwdoVK1a09saNG512Xpk/9f3++OOPra39YiRemZ418rnRGUwl8nnI6LB66U8iMx/rLMhZET+fG0JI9oArMoQQQggJLJzIEEIIISSwZIrMvtu3b3e2ddikRBYUq1ChgrV18TiJlKN0IUAZeiyPLbP8Am44sJQVdNiwJLOGX+tsqP/85z+tLaW8UIvnadlG9sXKlSudfTfccIO1ZQiwPpcMo5XF8Tp06OC0u/3220O6Rq8Qcy1NSJlGFziUZNa+JYSQ7AZXZAghhBASWDiRIYQQQkhg4USGEEIIIYElU4Rfaz8FWQ7Az1dF+tLIStiA61chw7t1KnX9uUS034e8RlkOwS89vV8V4YxEpvIH3PtTrFgxa8t7CLj3RIZi6+8p/Uy0L8nq1autXapUKWvXrVvXaSfLF+zYscPaM2fOhBfSN0c+J0DSNPyJePU/ABQtWtRzHyGEkMwBV2QIIYQQElg4kSGEEEJIYMkU0pIOjZUyjl76L1KkiLWlhKGlBPk5eTxdTfvUqVPWlvKDlkS8JCRdTVsSagXf9KZbt27O9rRp06y9efNma8twdMA7W7JfCHPevHmdffJzv/zyi7VluDXgZllOSEhI+iWSQWeBlniF9OvPyIzCfuHnUmbzOy8hhJC0JXP+0hJCCCGEhAAnMoQQQggJLJliTXzLli3OtpQVtCRw5MiRZG0tQR06dMjax44ds/bWrVuddvv27bP2unXrrN2wYUOnnZRZpOzklTE2M6PlnkWLFll7165d1p44caLT7rPPPrO2jCryi/wJFV2Q8vPPP7d28+bNr/j4lSpVSvbv8lkD3GzR1157refxMrpQJCGEkL/gigwhhBBCAgsnMoQQQggJLJzIEEIIISSwhJl0LOMrQ1alj8GIESOcdgcPHrS2DLcG3DDr2NjYZI8HALt3707Wvv766512Mhvszp07ra3DrfPly2dt6UszfPhwp50M7/bLDpyV0D5Osqq19GMC3Psj/VG8fFguB6/nS7NkyRJr6+dLXp/MckwIISRzwhUZQgghhAQWTmQIIYQQEljSVVoihBBCCElNuCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDCiQwhhBBCAgsnMoQQQggJLJzIEEIIISSwcCJDCCGEkMDy/wDiQ8cuwhQK/QAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.629606800Z",
     "start_time": "2024-07-17T03:06:34.495968400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 从数据集到dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=32, shuffle=True) #batch_size分批，shuffle洗牌\n",
    "val_loader = torch.utils.data.DataLoader(test_ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "在PyTorch中，`DataLoader`是一个迭代器，它封装了数据的加载和预处理过程，使得在训练机器学习模型时可以方便地批量加载数据。`DataLoader`主要负责以下几个方面：\n",
    "\n",
    "1. **批量加载数据**：`DataLoader`可以将数据集（Dataset）切分为更小的批次（batch），每次迭代提供一小批量数据，而不是单个数据点。这有助于模型学习数据中的统计依赖性，并且可以更高效地利用GPU等硬件的并行计算能力。\n",
    "\n",
    "2. **数据打乱**：默认情况下，`DataLoader`会在每个epoch（训练周期）开始时打乱数据的顺序。这有助于模型训练时避免陷入局部最优解，并且可以提高模型的泛化能力。\n",
    "\n",
    "3. **多线程数据加载**：`DataLoader`支持多线程（通过参数`num_workers`）来并行地加载数据，这可以显著减少训练过程中的等待时间，尤其是在处理大规模数据集时。\n",
    "\n",
    "4. **数据预处理**：`DataLoader`可以与`transforms`结合使用，对加载的数据进行预处理，如归一化、标准化、数据增强等操作。\n",
    "\n",
    "5. **内存管理**：`DataLoader`负责管理数据的内存使用，确保在训练过程中不会耗尽内存资源。\n",
    "\n",
    "6. **易用性**：`DataLoader`提供了一个简单的接口，可以很容易地集成到训练循环中。\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T18:00:03.369555Z",
     "start_time": "2026-02-09T18:00:03.362873Z"
    }
   },
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # 继承父类的初始化方法，子类有父类的属性\n",
    "        self.flatten = nn.Flatten()  # 展平层\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(784, 300),  # in_features=784, out_features=300, 784是输入特征数，300是输出特征数\n",
    "            nn.ReLU(), # 激活函数\n",
    "            nn.Linear(300, 100),#隐藏层神经元数100\n",
    "            nn.ReLU(), # 激活函数\n",
    "            nn.Linear(100, 10),#输出层神经元数10\n",
    "        )\n",
    "\n",
    "    def forward(self, x): # 前向计算\n",
    "        # x.shape [batch size, 1, 28, 28]\n",
    "        x = self.flatten(x)  \n",
    "        # 展平后 x.shape [batch size, 784]\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # logits.shape [batch size, 10]\n",
    "        return logits #没有经过softmax,称为logits\n",
    "    \n",
    "model = NeuralNetwork()"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T18:08:30.878440Z",
     "start_time": "2026-02-09T18:08:30.873991Z"
    }
   },
   "source": [
    "# 看看网络结构\n",
    "model"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [
    "784*300+300+300*100+100+100*10+10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.633643600Z",
     "start_time": "2026-02-08T18:46:01.148121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266610"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.634648100Z",
     "start_time": "2026-02-08T18:46:04.142756Z"
    }
   },
   "source": [
    "for name, param in model.named_parameters(): # 打印模型参数\n",
    "      print(name, param.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_relu_stack.0.weight torch.Size([300, 784])\n",
      "linear_relu_stack.0.bias torch.Size([300])\n",
      "linear_relu_stack.2.weight torch.Size([100, 300])\n",
      "linear_relu_stack.2.bias torch.Size([100])\n",
      "linear_relu_stack.4.weight torch.Size([10, 100])\n",
      "linear_relu_stack.4.bias torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.636325300Z",
     "start_time": "2026-02-08T18:46:09.565066Z"
    }
   },
   "source": [
    "# 看看模型参数\n",
    "list(model.parameters())  # 这种方法拿到模型的所有可学习参数,requires_grad=True\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0248,  0.0220, -0.0079,  ..., -0.0256,  0.0226,  0.0166],\n",
       "         [-0.0147,  0.0261,  0.0051,  ...,  0.0341, -0.0191, -0.0299],\n",
       "         [-0.0014,  0.0155, -0.0125,  ..., -0.0067,  0.0349, -0.0349],\n",
       "         ...,\n",
       "         [ 0.0293, -0.0342,  0.0205,  ...,  0.0336,  0.0160, -0.0179],\n",
       "         [-0.0121, -0.0043,  0.0279,  ...,  0.0283,  0.0161, -0.0196],\n",
       "         [-0.0242,  0.0085,  0.0276,  ..., -0.0084, -0.0152,  0.0201]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 3.2570e-02,  1.7110e-02, -1.1270e-02, -2.6225e-02,  1.3314e-02,\n",
       "          3.4090e-02, -3.5700e-02,  1.9428e-02, -1.8835e-02,  6.1714e-03,\n",
       "         -3.3722e-02,  3.0109e-02,  3.4136e-02, -8.3029e-03, -1.1094e-02,\n",
       "         -1.8204e-02,  1.9296e-02,  8.7865e-03, -1.6620e-02, -3.0145e-02,\n",
       "          2.4870e-02,  3.1302e-02, -1.9092e-04,  9.9755e-03,  6.0876e-03,\n",
       "         -3.2198e-02,  2.5315e-02, -2.8823e-02, -2.9530e-02, -1.2327e-02,\n",
       "         -1.0285e-02, -3.5252e-02, -1.6970e-02, -2.0722e-02,  8.9230e-03,\n",
       "          2.7845e-02,  1.7136e-03,  3.1033e-02,  9.3141e-03, -1.9355e-02,\n",
       "          1.2331e-03,  2.7028e-02,  1.4502e-02,  2.6522e-02, -2.6477e-02,\n",
       "         -3.1071e-02, -2.2566e-02,  2.8907e-02,  3.1773e-02, -2.7367e-02,\n",
       "         -2.8364e-03,  2.5239e-02,  2.1147e-02,  1.8610e-02,  2.5669e-02,\n",
       "          2.9416e-03, -2.8472e-02,  3.1831e-02,  1.8561e-02, -2.1186e-02,\n",
       "         -1.2481e-02, -5.7548e-03,  2.8217e-02, -1.1407e-03,  9.8796e-03,\n",
       "          6.6590e-03, -2.2767e-02, -1.5382e-02, -1.7137e-02,  1.1247e-02,\n",
       "         -2.1171e-02,  2.6661e-02,  1.2341e-02,  4.9048e-03,  2.0102e-02,\n",
       "         -5.5747e-03, -4.4426e-03, -2.3584e-02, -6.5601e-03,  3.2230e-02,\n",
       "         -2.0956e-02, -2.2443e-03,  1.9333e-03,  4.5497e-03, -4.2268e-03,\n",
       "         -5.1176e-03,  3.1027e-03,  3.9855e-03, -9.4845e-03, -1.8137e-02,\n",
       "          3.7896e-03,  1.8385e-02,  1.2671e-02, -7.0705e-03, -1.5884e-02,\n",
       "         -3.5621e-02, -2.5827e-02,  4.6804e-03,  1.6722e-04,  7.6022e-03,\n",
       "         -3.4965e-02,  2.6912e-02,  2.4124e-02, -1.1395e-02, -3.3101e-02,\n",
       "          2.9139e-03,  1.1284e-02, -2.3249e-02,  2.5103e-02, -1.2752e-02,\n",
       "         -3.8110e-03,  2.6616e-02,  1.4075e-02, -2.3150e-02, -2.8755e-02,\n",
       "         -2.1061e-04, -3.6210e-03, -1.6581e-02,  1.0939e-03,  4.5528e-03,\n",
       "          2.7007e-02,  1.5755e-02,  1.9526e-02, -1.2709e-02, -7.1586e-03,\n",
       "          2.5705e-02, -5.1097e-03,  1.0602e-02,  2.6392e-02,  6.7994e-03,\n",
       "         -5.8609e-03,  8.4810e-03, -3.1867e-02, -1.9325e-02,  2.7870e-02,\n",
       "          2.4115e-02,  3.1408e-02,  4.2531e-03, -1.7232e-02,  3.4908e-03,\n",
       "          2.8228e-02, -1.7415e-02,  3.3633e-02, -2.9377e-02,  2.3418e-02,\n",
       "          2.9863e-02,  3.2738e-02,  8.8264e-03,  9.6727e-05, -1.8447e-02,\n",
       "          2.5232e-02, -3.5152e-02, -1.3081e-02,  1.4559e-02,  1.6040e-02,\n",
       "         -2.1231e-02, -9.9632e-03, -1.0873e-02,  2.0954e-02,  1.7606e-02,\n",
       "         -2.8551e-02,  3.1550e-02, -3.1887e-02, -7.5265e-03, -7.5170e-03,\n",
       "         -1.9618e-02,  2.6173e-02,  3.4293e-02, -1.7010e-02, -3.2332e-02,\n",
       "         -2.2724e-02, -2.2669e-02,  2.8722e-02, -6.9763e-03, -7.5863e-03,\n",
       "          3.0314e-02, -1.8435e-02,  2.1700e-02, -2.7955e-02,  1.3188e-03,\n",
       "         -2.1336e-02,  2.0364e-02, -2.5057e-02, -2.2774e-02, -2.2135e-02,\n",
       "         -1.7143e-02,  3.7845e-04, -3.1644e-02,  1.7404e-02,  2.8863e-02,\n",
       "          2.4379e-02,  3.3077e-02, -9.3545e-03, -1.2306e-02, -3.2474e-02,\n",
       "          1.7736e-02, -1.4237e-02, -2.8187e-02, -3.4704e-02, -2.0264e-02,\n",
       "          2.5365e-02,  2.1690e-02,  5.2458e-03, -7.9327e-03,  1.3972e-02,\n",
       "         -1.6368e-02, -1.3604e-02,  3.0151e-02, -9.2422e-03,  3.0607e-02,\n",
       "          2.9394e-02, -2.0941e-02,  3.1287e-02, -1.1937e-02,  8.5555e-03,\n",
       "         -2.4995e-02,  7.2574e-03, -3.5686e-02,  3.3375e-05, -3.3315e-02,\n",
       "          1.5438e-02,  3.4202e-02,  2.5495e-02, -8.7660e-03,  9.1271e-03,\n",
       "          5.3699e-03, -1.5076e-02,  1.2770e-02,  2.0606e-02,  2.4034e-02,\n",
       "          1.5847e-02, -3.1228e-02,  3.4925e-02,  2.2897e-02,  3.3180e-02,\n",
       "          8.7065e-03,  2.2177e-02,  1.2064e-02, -3.3404e-02, -2.9205e-02,\n",
       "         -4.8639e-03, -9.2930e-03,  9.9158e-03, -1.7130e-02,  2.2213e-02,\n",
       "         -3.2986e-03, -1.4044e-02, -1.7992e-02,  1.5493e-02, -3.5403e-03,\n",
       "          3.5433e-02, -1.0589e-02,  2.3239e-02, -1.8258e-02, -2.0567e-02,\n",
       "         -1.3175e-02, -8.8046e-03,  6.5166e-03,  2.7324e-02, -4.3783e-03,\n",
       "          8.8558e-03,  1.4860e-03,  1.0694e-02,  7.0219e-03,  3.4954e-02,\n",
       "          1.5846e-02,  1.2255e-03,  2.3484e-02, -1.5723e-02, -2.1666e-02,\n",
       "          3.4868e-02, -1.2183e-02,  1.6144e-02, -1.9110e-02,  8.1129e-03,\n",
       "          1.0515e-02, -7.7455e-03,  2.5124e-02,  2.9251e-02, -3.3512e-02,\n",
       "          3.2176e-03,  3.1412e-02,  1.9444e-02, -1.1482e-02, -1.2702e-02,\n",
       "         -2.7184e-02, -3.1665e-02,  3.0546e-02,  3.4607e-02, -2.6957e-02,\n",
       "          5.1671e-03, -2.1885e-02,  2.6701e-02,  2.2325e-02,  6.0068e-03,\n",
       "         -1.1425e-02, -1.0244e-02,  1.0491e-02,  2.1894e-02, -6.2123e-03],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0190, -0.0493,  0.0489,  ..., -0.0486,  0.0267, -0.0200],\n",
       "         [-0.0086, -0.0555, -0.0382,  ...,  0.0264,  0.0313,  0.0136],\n",
       "         [-0.0550, -0.0269, -0.0419,  ..., -0.0253, -0.0435,  0.0418],\n",
       "         ...,\n",
       "         [-0.0233, -0.0352, -0.0236,  ...,  0.0339,  0.0247, -0.0242],\n",
       "         [ 0.0515, -0.0210, -0.0373,  ...,  0.0356,  0.0047, -0.0317],\n",
       "         [-0.0418,  0.0120, -0.0248,  ..., -0.0223, -0.0424,  0.0035]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0132,  0.0413, -0.0352, -0.0443, -0.0176,  0.0266,  0.0113, -0.0537,\n",
       "          0.0555, -0.0262, -0.0472,  0.0105, -0.0230, -0.0365,  0.0004,  0.0137,\n",
       "         -0.0174,  0.0052,  0.0544,  0.0520,  0.0329,  0.0472,  0.0260,  0.0197,\n",
       "          0.0024, -0.0382,  0.0330, -0.0346, -0.0045, -0.0198,  0.0416, -0.0014,\n",
       "          0.0130, -0.0324, -0.0197,  0.0498, -0.0370,  0.0264,  0.0428, -0.0553,\n",
       "          0.0562, -0.0123,  0.0378,  0.0272, -0.0472,  0.0155, -0.0141, -0.0381,\n",
       "          0.0538,  0.0334,  0.0316, -0.0185,  0.0084, -0.0169, -0.0405, -0.0347,\n",
       "          0.0351,  0.0296,  0.0083,  0.0091,  0.0517,  0.0411,  0.0541,  0.0149,\n",
       "          0.0057,  0.0185,  0.0022, -0.0188, -0.0451,  0.0520, -0.0111, -0.0339,\n",
       "          0.0267,  0.0242, -0.0224,  0.0318,  0.0379, -0.0340, -0.0100, -0.0063,\n",
       "         -0.0447,  0.0461,  0.0254,  0.0190, -0.0541, -0.0258, -0.0090,  0.0152,\n",
       "          0.0448, -0.0105, -0.0059, -0.0289, -0.0570,  0.0550, -0.0373,  0.0313,\n",
       "         -0.0492, -0.0080,  0.0276, -0.0522], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0481,  0.0649, -0.0057,  0.0883, -0.0421, -0.0972,  0.0122,  0.0175,\n",
       "          -0.0040, -0.0454, -0.0225, -0.0275, -0.0726, -0.0122, -0.0459,  0.0533,\n",
       "          -0.0727,  0.0108,  0.0141, -0.0882,  0.0954,  0.0371, -0.0535, -0.0543,\n",
       "          -0.0249, -0.0389, -0.0599,  0.0600, -0.0278,  0.0873,  0.0701, -0.0327,\n",
       "           0.0033,  0.0176, -0.0792, -0.0348, -0.0640,  0.0984,  0.0782,  0.0817,\n",
       "           0.0189,  0.0606, -0.0006, -0.0439, -0.0082,  0.0595,  0.0052,  0.0797,\n",
       "           0.0976, -0.0135, -0.0318, -0.0292,  0.0302, -0.0284,  0.0793, -0.0901,\n",
       "          -0.0257, -0.0376,  0.0524,  0.0961,  0.0368,  0.0131, -0.0218, -0.0607,\n",
       "          -0.0913,  0.0585,  0.0702, -0.0558,  0.0716, -0.0848, -0.0038, -0.0741,\n",
       "           0.0182, -0.0476,  0.0819,  0.0591,  0.0782, -0.0748, -0.0992,  0.0033,\n",
       "          -0.0538,  0.0364,  0.0446, -0.0009,  0.0971,  0.0774,  0.0382,  0.0247,\n",
       "           0.0871, -0.0413,  0.0092,  0.0050, -0.0979,  0.0725,  0.0448, -0.0215,\n",
       "          -0.0955, -0.0685, -0.0733,  0.0098],\n",
       "         [-0.0786,  0.0851,  0.0023, -0.0129, -0.0264, -0.0098, -0.0716, -0.0386,\n",
       "           0.0343, -0.0820, -0.0457,  0.0491, -0.0707,  0.0631, -0.0724, -0.0513,\n",
       "          -0.0093,  0.0914,  0.0755,  0.0641, -0.0360, -0.0964, -0.0340,  0.0382,\n",
       "           0.0901,  0.0468,  0.0269,  0.0381,  0.0498, -0.0635,  0.0069,  0.0511,\n",
       "           0.0099,  0.0095, -0.0571, -0.0287, -0.0971, -0.0007,  0.0260,  0.0007,\n",
       "          -0.0497,  0.0187, -0.0262,  0.0036, -0.0025, -0.0341,  0.0772,  0.0794,\n",
       "          -0.0265,  0.0495, -0.0136, -0.0752,  0.0673, -0.0641,  0.0271,  0.0398,\n",
       "           0.0619,  0.0623, -0.0094,  0.0149, -0.0853,  0.0929,  0.0505,  0.0065,\n",
       "           0.0326,  0.0846,  0.0071,  0.0668,  0.0700, -0.0278, -0.0341, -0.0841,\n",
       "          -0.0823,  0.0690,  0.0188,  0.0471,  0.0058,  0.0823, -0.0813,  0.0697,\n",
       "           0.0793, -0.0606,  0.0464,  0.0957,  0.0148, -0.0537, -0.0435, -0.0687,\n",
       "           0.0438, -0.0302,  0.0927, -0.0331, -0.0598,  0.0994, -0.0064,  0.0250,\n",
       "           0.0503, -0.0165,  0.0812, -0.0834],\n",
       "         [-0.0516,  0.0381, -0.0795,  0.0328,  0.0342,  0.0343,  0.0989, -0.0471,\n",
       "          -0.0902, -0.0962, -0.0543, -0.0626,  0.0360, -0.0956, -0.0646,  0.0004,\n",
       "           0.0301,  0.0429,  0.0472,  0.0006, -0.0988,  0.0223, -0.0877,  0.0078,\n",
       "          -0.0853, -0.0673,  0.0718, -0.0965, -0.0304,  0.0583, -0.0268, -0.0860,\n",
       "           0.0510,  0.0029,  0.0372,  0.0681, -0.0257, -0.0812,  0.0405,  0.0780,\n",
       "           0.0018,  0.0573,  0.0888, -0.0673, -0.0899,  0.0113, -0.0014, -0.0601,\n",
       "           0.0980, -0.0779,  0.0294, -0.0483, -0.0435, -0.0566,  0.0288,  0.0515,\n",
       "           0.0255, -0.0635, -0.0251, -0.0139, -0.0622,  0.0427,  0.0988,  0.0830,\n",
       "           0.0611, -0.0764,  0.0222,  0.0917,  0.0587, -0.0419,  0.0416, -0.0156,\n",
       "           0.0766, -0.0002, -0.0778, -0.0441, -0.0305, -0.0953, -0.0649,  0.0279,\n",
       "           0.0107, -0.0005, -0.0956,  0.0023,  0.0843,  0.0896,  0.0491, -0.0159,\n",
       "           0.0072, -0.0065,  0.0530, -0.0527, -0.0887,  0.0360, -0.0002, -0.0877,\n",
       "           0.0118,  0.0164, -0.0959, -0.0650],\n",
       "         [ 0.0556,  0.0765,  0.0375, -0.0225, -0.0388,  0.0791, -0.0092,  0.0673,\n",
       "           0.0546, -0.0202,  0.0551,  0.0351, -0.0499, -0.0219, -0.0630, -0.0334,\n",
       "          -0.0626, -0.0729, -0.0821,  0.0772, -0.0335, -0.0073,  0.0553,  0.0305,\n",
       "          -0.0586,  0.0320, -0.0420, -0.0673,  0.0951,  0.0566,  0.0566,  0.0327,\n",
       "           0.0387, -0.0437, -0.0669, -0.0110, -0.0590, -0.0537, -0.0176, -0.0134,\n",
       "          -0.0386, -0.0397, -0.0685,  0.0973,  0.0233,  0.0022,  0.0319, -0.0275,\n",
       "           0.0445,  0.0913, -0.0595,  0.0435,  0.0676, -0.0183, -0.0102, -0.0145,\n",
       "          -0.0804,  0.0676,  0.0833, -0.0815, -0.0696,  0.0005, -0.0696,  0.0454,\n",
       "          -0.0848,  0.0247, -0.0757, -0.0098,  0.0179,  0.0004,  0.0739,  0.0755,\n",
       "          -0.0710, -0.0290,  0.0737,  0.0979, -0.0889,  0.0464,  0.0761,  0.0926,\n",
       "          -0.0789, -0.0662, -0.0162, -0.0927,  0.0910,  0.0734, -0.0322,  0.0934,\n",
       "          -0.0514,  0.0550, -0.0859,  0.0491, -0.0439,  0.0350, -0.0766, -0.0775,\n",
       "          -0.0670, -0.0898, -0.0802, -0.0251],\n",
       "         [-0.0052, -0.0134,  0.0351,  0.0040, -0.0749,  0.0466,  0.0049,  0.0396,\n",
       "           0.0453, -0.0673, -0.0379,  0.0824, -0.0045, -0.0954,  0.0570,  0.0253,\n",
       "           0.0968,  0.0564,  0.0963,  0.0082, -0.0093, -0.0976, -0.0711, -0.0536,\n",
       "          -0.0661, -0.0547, -0.0622,  0.0723,  0.0787,  0.0524,  0.0159,  0.0159,\n",
       "           0.0953, -0.0696,  0.0323,  0.0780,  0.0964,  0.0062, -0.0403, -0.0347,\n",
       "          -0.0469, -0.0450,  0.0968, -0.0127, -0.0884, -0.0528, -0.0291,  0.0008,\n",
       "          -0.0966, -0.0429,  0.0564,  0.0178, -0.0569, -0.0700, -0.0663, -0.0654,\n",
       "          -0.0522,  0.0888, -0.0980, -0.0941, -0.0109,  0.0986, -0.0345,  0.0337,\n",
       "           0.0755, -0.0383,  0.0941, -0.0766, -0.0038, -0.0168,  0.0685, -0.0559,\n",
       "           0.0118,  0.0054,  0.0390, -0.0926,  0.0446,  0.0810,  0.0260, -0.0002,\n",
       "          -0.0382,  0.0630,  0.0304, -0.0611,  0.0783,  0.0056, -0.0986,  0.0442,\n",
       "           0.0393,  0.0029,  0.0104,  0.0717,  0.0095,  0.0767, -0.0008,  0.0567,\n",
       "          -0.0171, -0.0318,  0.0241,  0.0363],\n",
       "         [-0.0394,  0.0168,  0.0835, -0.0652, -0.0253, -0.0116, -0.0588,  0.0655,\n",
       "           0.0425,  0.0468,  0.0907,  0.0418, -0.0369, -0.0337, -0.0556,  0.0857,\n",
       "           0.0632, -0.0276,  0.0718, -0.0081,  0.0741,  0.0280,  0.0192, -0.0388,\n",
       "          -0.0121, -0.0151,  0.0449,  0.0049,  0.0927, -0.0677,  0.0812,  0.0392,\n",
       "           0.0442,  0.0032, -0.0621,  0.0143,  0.0973, -0.0992, -0.0245, -0.0374,\n",
       "          -0.0506, -0.0699, -0.0445, -0.0909,  0.0910, -0.0280,  0.0364,  0.0225,\n",
       "          -0.0994, -0.0253, -0.0577,  0.0077, -0.0242, -0.0082, -0.0784, -0.0155,\n",
       "           0.0830, -0.0935, -0.0289,  0.0892,  0.0148, -0.0110, -0.0141, -0.0032,\n",
       "          -0.0324, -0.0855, -0.0810, -0.0703,  0.0183,  0.0870, -0.0804,  0.0477,\n",
       "          -0.0874,  0.0828,  0.0729, -0.0789, -0.0031,  0.0607, -0.0124, -0.0424,\n",
       "          -0.0955,  0.0278, -0.0533,  0.0967, -0.0911, -0.0994,  0.0108,  0.0037,\n",
       "           0.0621,  0.0913,  0.0662, -0.0862,  0.0325,  0.0937,  0.0427, -0.0482,\n",
       "           0.0071,  0.0373, -0.0073, -0.0067],\n",
       "         [ 0.0687, -0.0709,  0.0087,  0.0242,  0.0493,  0.0346,  0.0632, -0.0569,\n",
       "           0.0769, -0.0998,  0.0859, -0.0738,  0.0368, -0.0797,  0.0213, -0.0315,\n",
       "          -0.0554,  0.0818, -0.0738, -0.0052, -0.0185,  0.0904,  0.0561,  0.0167,\n",
       "           0.0253, -0.0240, -0.0884, -0.0601, -0.0346,  0.0459, -0.0988,  0.0577,\n",
       "           0.0684, -0.0300, -0.0656, -0.0856,  0.0912,  0.0378, -0.0609, -0.0786,\n",
       "           0.0510,  0.0498,  0.0059,  0.0850, -0.0997, -0.0715, -0.0817, -0.0782,\n",
       "           0.0717,  0.0734,  0.0269, -0.0190,  0.0049,  0.0627,  0.0986,  0.0987,\n",
       "          -0.0045, -0.0674,  0.0902, -0.0788, -0.0387,  0.0800, -0.0006, -0.0108,\n",
       "          -0.0750,  0.0995,  0.0973,  0.0128, -0.0391,  0.0913,  0.0015,  0.0170,\n",
       "           0.0162, -0.0680, -0.0901, -0.0477, -0.0015,  0.0872, -0.0305,  0.0408,\n",
       "          -0.0272, -0.0271, -0.0846, -0.0610,  0.0645,  0.0155,  0.0094, -0.0815,\n",
       "          -0.0328, -0.0351, -0.0361,  0.0687,  0.0475, -0.0806, -0.0721, -0.0630,\n",
       "           0.0497, -0.0905,  0.0610, -0.0839],\n",
       "         [-0.0991, -0.0983,  0.0729,  0.0490,  0.0528,  0.0084,  0.0070, -0.0084,\n",
       "          -0.0699, -0.0047,  0.0212,  0.0047, -0.0122, -0.0005,  0.0509, -0.0774,\n",
       "          -0.0355,  0.0004,  0.0370,  0.0357, -0.0483,  0.0565, -0.0446, -0.0203,\n",
       "          -0.0660,  0.0641, -0.0009, -0.0400,  0.0500, -0.0501,  0.0563,  0.0083,\n",
       "          -0.0443, -0.0216,  0.0213, -0.0881,  0.0532, -0.0934,  0.0049,  0.0837,\n",
       "          -0.0239, -0.0043, -0.0608,  0.0166, -0.0336,  0.0444, -0.0287, -0.0042,\n",
       "           0.0648,  0.0092,  0.0754,  0.0398, -0.0099, -0.0403, -0.0883,  0.0738,\n",
       "          -0.0183, -0.0285, -0.0436,  0.0825,  0.0853, -0.0836,  0.0765, -0.0220,\n",
       "          -0.0316, -0.0709,  0.0035, -0.0027,  0.0702,  0.0817, -0.0544,  0.0380,\n",
       "           0.0230, -0.0703, -0.0577, -0.0133, -0.0891, -0.0995, -0.0771, -0.0518,\n",
       "          -0.0051, -0.0536,  0.0688, -0.0220,  0.0171,  0.0065, -0.0284,  0.0055,\n",
       "           0.0453,  0.0890,  0.0950, -0.0483, -0.0228,  0.0388,  0.0599, -0.0273,\n",
       "          -0.0921, -0.0113, -0.0042,  0.0780],\n",
       "         [-0.0426,  0.0102,  0.0569,  0.0562, -0.0226,  0.0703, -0.0514, -0.0136,\n",
       "           0.0233, -0.0083, -0.0300, -0.0968, -0.0167, -0.0337, -0.0113, -0.0867,\n",
       "           0.0365,  0.0459,  0.0896, -0.0791, -0.0293, -0.0878, -0.0716,  0.0955,\n",
       "           0.0964,  0.0731, -0.0533, -0.0783,  0.0300, -0.0296,  0.0397, -0.0124,\n",
       "           0.0640, -0.0889,  0.0855,  0.0885,  0.0482,  0.0546, -0.0136,  0.0113,\n",
       "          -0.0962, -0.0714,  0.0585, -0.0514, -0.0272, -0.0107,  0.0567, -0.0931,\n",
       "          -0.0490,  0.0154,  0.0473,  0.0888,  0.0788,  0.0473,  0.0920,  0.0914,\n",
       "           0.0602,  0.0556, -0.0118, -0.0625, -0.0080,  0.0719,  0.0226,  0.0826,\n",
       "           0.0150,  0.0860, -0.0945, -0.0410,  0.0512, -0.0726, -0.0102,  0.0112,\n",
       "           0.0679,  0.0056,  0.0731,  0.0447, -0.0698, -0.0859, -0.0821,  0.0890,\n",
       "          -0.0921, -0.0386,  0.0307, -0.0619,  0.0581, -0.0966, -0.0984,  0.0825,\n",
       "          -0.0609,  0.0399, -0.0422,  0.0971, -0.0861, -0.0911, -0.0707, -0.0833,\n",
       "           0.0621,  0.0757,  0.0586, -0.0722],\n",
       "         [ 0.0444,  0.0952, -0.0479, -0.0254,  0.0646, -0.0376,  0.0055, -0.0737,\n",
       "           0.0909,  0.0891, -0.0501, -0.0945,  0.0969, -0.0313, -0.0773,  0.0605,\n",
       "           0.0602,  0.0471,  0.0414,  0.0375,  0.0844, -0.0436, -0.0220,  0.0138,\n",
       "          -0.0427,  0.0573,  0.0447,  0.0155,  0.0206,  0.0018, -0.0574, -0.0849,\n",
       "          -0.0701,  0.0371,  0.0235,  0.0804, -0.0513, -0.0695,  0.0570,  0.0543,\n",
       "          -0.0493, -0.0915, -0.0962,  0.0986,  0.0431,  0.0517, -0.0158, -0.0601,\n",
       "          -0.0666,  0.0089, -0.0820, -0.0985,  0.0925,  0.0005, -0.0997,  0.0688,\n",
       "           0.0487,  0.0573, -0.0230, -0.0683,  0.0625, -0.0492,  0.0721,  0.0926,\n",
       "           0.0805, -0.0912,  0.0060,  0.0939,  0.0045, -0.0710, -0.0246,  0.0658,\n",
       "          -0.0665, -0.0932, -0.0886, -0.0260, -0.0332,  0.0528, -0.0763, -0.0097,\n",
       "          -0.0738,  0.0151,  0.0712, -0.0721,  0.0687, -0.0933, -0.0914, -0.0081,\n",
       "           0.0444,  0.0198, -0.0730,  0.0477,  0.0103,  0.0820, -0.0611, -0.0003,\n",
       "          -0.0510, -0.0452,  0.0075,  0.0983]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0280, -0.0960,  0.0731, -0.0127,  0.0094,  0.0376, -0.0396,  0.0637,\n",
       "          0.0508,  0.0566], requires_grad=True)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.637833500Z",
     "start_time": "2026-02-08T18:46:21.492695Z"
    }
   },
   "source": "model.state_dict()  # 这种方法用于保存模型参数，看能看见参数属于模型的哪一部分",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear_relu_stack.0.weight',\n",
       "              tensor([[-0.0248,  0.0220, -0.0079,  ..., -0.0256,  0.0226,  0.0166],\n",
       "                      [-0.0147,  0.0261,  0.0051,  ...,  0.0341, -0.0191, -0.0299],\n",
       "                      [-0.0014,  0.0155, -0.0125,  ..., -0.0067,  0.0349, -0.0349],\n",
       "                      ...,\n",
       "                      [ 0.0293, -0.0342,  0.0205,  ...,  0.0336,  0.0160, -0.0179],\n",
       "                      [-0.0121, -0.0043,  0.0279,  ...,  0.0283,  0.0161, -0.0196],\n",
       "                      [-0.0242,  0.0085,  0.0276,  ..., -0.0084, -0.0152,  0.0201]])),\n",
       "             ('linear_relu_stack.0.bias',\n",
       "              tensor([ 3.2570e-02,  1.7110e-02, -1.1270e-02, -2.6225e-02,  1.3314e-02,\n",
       "                       3.4090e-02, -3.5700e-02,  1.9428e-02, -1.8835e-02,  6.1714e-03,\n",
       "                      -3.3722e-02,  3.0109e-02,  3.4136e-02, -8.3029e-03, -1.1094e-02,\n",
       "                      -1.8204e-02,  1.9296e-02,  8.7865e-03, -1.6620e-02, -3.0145e-02,\n",
       "                       2.4870e-02,  3.1302e-02, -1.9092e-04,  9.9755e-03,  6.0876e-03,\n",
       "                      -3.2198e-02,  2.5315e-02, -2.8823e-02, -2.9530e-02, -1.2327e-02,\n",
       "                      -1.0285e-02, -3.5252e-02, -1.6970e-02, -2.0722e-02,  8.9230e-03,\n",
       "                       2.7845e-02,  1.7136e-03,  3.1033e-02,  9.3141e-03, -1.9355e-02,\n",
       "                       1.2331e-03,  2.7028e-02,  1.4502e-02,  2.6522e-02, -2.6477e-02,\n",
       "                      -3.1071e-02, -2.2566e-02,  2.8907e-02,  3.1773e-02, -2.7367e-02,\n",
       "                      -2.8364e-03,  2.5239e-02,  2.1147e-02,  1.8610e-02,  2.5669e-02,\n",
       "                       2.9416e-03, -2.8472e-02,  3.1831e-02,  1.8561e-02, -2.1186e-02,\n",
       "                      -1.2481e-02, -5.7548e-03,  2.8217e-02, -1.1407e-03,  9.8796e-03,\n",
       "                       6.6590e-03, -2.2767e-02, -1.5382e-02, -1.7137e-02,  1.1247e-02,\n",
       "                      -2.1171e-02,  2.6661e-02,  1.2341e-02,  4.9048e-03,  2.0102e-02,\n",
       "                      -5.5747e-03, -4.4426e-03, -2.3584e-02, -6.5601e-03,  3.2230e-02,\n",
       "                      -2.0956e-02, -2.2443e-03,  1.9333e-03,  4.5497e-03, -4.2268e-03,\n",
       "                      -5.1176e-03,  3.1027e-03,  3.9855e-03, -9.4845e-03, -1.8137e-02,\n",
       "                       3.7896e-03,  1.8385e-02,  1.2671e-02, -7.0705e-03, -1.5884e-02,\n",
       "                      -3.5621e-02, -2.5827e-02,  4.6804e-03,  1.6722e-04,  7.6022e-03,\n",
       "                      -3.4965e-02,  2.6912e-02,  2.4124e-02, -1.1395e-02, -3.3101e-02,\n",
       "                       2.9139e-03,  1.1284e-02, -2.3249e-02,  2.5103e-02, -1.2752e-02,\n",
       "                      -3.8110e-03,  2.6616e-02,  1.4075e-02, -2.3150e-02, -2.8755e-02,\n",
       "                      -2.1061e-04, -3.6210e-03, -1.6581e-02,  1.0939e-03,  4.5528e-03,\n",
       "                       2.7007e-02,  1.5755e-02,  1.9526e-02, -1.2709e-02, -7.1586e-03,\n",
       "                       2.5705e-02, -5.1097e-03,  1.0602e-02,  2.6392e-02,  6.7994e-03,\n",
       "                      -5.8609e-03,  8.4810e-03, -3.1867e-02, -1.9325e-02,  2.7870e-02,\n",
       "                       2.4115e-02,  3.1408e-02,  4.2531e-03, -1.7232e-02,  3.4908e-03,\n",
       "                       2.8228e-02, -1.7415e-02,  3.3633e-02, -2.9377e-02,  2.3418e-02,\n",
       "                       2.9863e-02,  3.2738e-02,  8.8264e-03,  9.6727e-05, -1.8447e-02,\n",
       "                       2.5232e-02, -3.5152e-02, -1.3081e-02,  1.4559e-02,  1.6040e-02,\n",
       "                      -2.1231e-02, -9.9632e-03, -1.0873e-02,  2.0954e-02,  1.7606e-02,\n",
       "                      -2.8551e-02,  3.1550e-02, -3.1887e-02, -7.5265e-03, -7.5170e-03,\n",
       "                      -1.9618e-02,  2.6173e-02,  3.4293e-02, -1.7010e-02, -3.2332e-02,\n",
       "                      -2.2724e-02, -2.2669e-02,  2.8722e-02, -6.9763e-03, -7.5863e-03,\n",
       "                       3.0314e-02, -1.8435e-02,  2.1700e-02, -2.7955e-02,  1.3188e-03,\n",
       "                      -2.1336e-02,  2.0364e-02, -2.5057e-02, -2.2774e-02, -2.2135e-02,\n",
       "                      -1.7143e-02,  3.7845e-04, -3.1644e-02,  1.7404e-02,  2.8863e-02,\n",
       "                       2.4379e-02,  3.3077e-02, -9.3545e-03, -1.2306e-02, -3.2474e-02,\n",
       "                       1.7736e-02, -1.4237e-02, -2.8187e-02, -3.4704e-02, -2.0264e-02,\n",
       "                       2.5365e-02,  2.1690e-02,  5.2458e-03, -7.9327e-03,  1.3972e-02,\n",
       "                      -1.6368e-02, -1.3604e-02,  3.0151e-02, -9.2422e-03,  3.0607e-02,\n",
       "                       2.9394e-02, -2.0941e-02,  3.1287e-02, -1.1937e-02,  8.5555e-03,\n",
       "                      -2.4995e-02,  7.2574e-03, -3.5686e-02,  3.3375e-05, -3.3315e-02,\n",
       "                       1.5438e-02,  3.4202e-02,  2.5495e-02, -8.7660e-03,  9.1271e-03,\n",
       "                       5.3699e-03, -1.5076e-02,  1.2770e-02,  2.0606e-02,  2.4034e-02,\n",
       "                       1.5847e-02, -3.1228e-02,  3.4925e-02,  2.2897e-02,  3.3180e-02,\n",
       "                       8.7065e-03,  2.2177e-02,  1.2064e-02, -3.3404e-02, -2.9205e-02,\n",
       "                      -4.8639e-03, -9.2930e-03,  9.9158e-03, -1.7130e-02,  2.2213e-02,\n",
       "                      -3.2986e-03, -1.4044e-02, -1.7992e-02,  1.5493e-02, -3.5403e-03,\n",
       "                       3.5433e-02, -1.0589e-02,  2.3239e-02, -1.8258e-02, -2.0567e-02,\n",
       "                      -1.3175e-02, -8.8046e-03,  6.5166e-03,  2.7324e-02, -4.3783e-03,\n",
       "                       8.8558e-03,  1.4860e-03,  1.0694e-02,  7.0219e-03,  3.4954e-02,\n",
       "                       1.5846e-02,  1.2255e-03,  2.3484e-02, -1.5723e-02, -2.1666e-02,\n",
       "                       3.4868e-02, -1.2183e-02,  1.6144e-02, -1.9110e-02,  8.1129e-03,\n",
       "                       1.0515e-02, -7.7455e-03,  2.5124e-02,  2.9251e-02, -3.3512e-02,\n",
       "                       3.2176e-03,  3.1412e-02,  1.9444e-02, -1.1482e-02, -1.2702e-02,\n",
       "                      -2.7184e-02, -3.1665e-02,  3.0546e-02,  3.4607e-02, -2.6957e-02,\n",
       "                       5.1671e-03, -2.1885e-02,  2.6701e-02,  2.2325e-02,  6.0068e-03,\n",
       "                      -1.1425e-02, -1.0244e-02,  1.0491e-02,  2.1894e-02, -6.2123e-03])),\n",
       "             ('linear_relu_stack.2.weight',\n",
       "              tensor([[-0.0190, -0.0493,  0.0489,  ..., -0.0486,  0.0267, -0.0200],\n",
       "                      [-0.0086, -0.0555, -0.0382,  ...,  0.0264,  0.0313,  0.0136],\n",
       "                      [-0.0550, -0.0269, -0.0419,  ..., -0.0253, -0.0435,  0.0418],\n",
       "                      ...,\n",
       "                      [-0.0233, -0.0352, -0.0236,  ...,  0.0339,  0.0247, -0.0242],\n",
       "                      [ 0.0515, -0.0210, -0.0373,  ...,  0.0356,  0.0047, -0.0317],\n",
       "                      [-0.0418,  0.0120, -0.0248,  ..., -0.0223, -0.0424,  0.0035]])),\n",
       "             ('linear_relu_stack.2.bias',\n",
       "              tensor([-0.0132,  0.0413, -0.0352, -0.0443, -0.0176,  0.0266,  0.0113, -0.0537,\n",
       "                       0.0555, -0.0262, -0.0472,  0.0105, -0.0230, -0.0365,  0.0004,  0.0137,\n",
       "                      -0.0174,  0.0052,  0.0544,  0.0520,  0.0329,  0.0472,  0.0260,  0.0197,\n",
       "                       0.0024, -0.0382,  0.0330, -0.0346, -0.0045, -0.0198,  0.0416, -0.0014,\n",
       "                       0.0130, -0.0324, -0.0197,  0.0498, -0.0370,  0.0264,  0.0428, -0.0553,\n",
       "                       0.0562, -0.0123,  0.0378,  0.0272, -0.0472,  0.0155, -0.0141, -0.0381,\n",
       "                       0.0538,  0.0334,  0.0316, -0.0185,  0.0084, -0.0169, -0.0405, -0.0347,\n",
       "                       0.0351,  0.0296,  0.0083,  0.0091,  0.0517,  0.0411,  0.0541,  0.0149,\n",
       "                       0.0057,  0.0185,  0.0022, -0.0188, -0.0451,  0.0520, -0.0111, -0.0339,\n",
       "                       0.0267,  0.0242, -0.0224,  0.0318,  0.0379, -0.0340, -0.0100, -0.0063,\n",
       "                      -0.0447,  0.0461,  0.0254,  0.0190, -0.0541, -0.0258, -0.0090,  0.0152,\n",
       "                       0.0448, -0.0105, -0.0059, -0.0289, -0.0570,  0.0550, -0.0373,  0.0313,\n",
       "                      -0.0492, -0.0080,  0.0276, -0.0522])),\n",
       "             ('linear_relu_stack.4.weight',\n",
       "              tensor([[-0.0481,  0.0649, -0.0057,  0.0883, -0.0421, -0.0972,  0.0122,  0.0175,\n",
       "                       -0.0040, -0.0454, -0.0225, -0.0275, -0.0726, -0.0122, -0.0459,  0.0533,\n",
       "                       -0.0727,  0.0108,  0.0141, -0.0882,  0.0954,  0.0371, -0.0535, -0.0543,\n",
       "                       -0.0249, -0.0389, -0.0599,  0.0600, -0.0278,  0.0873,  0.0701, -0.0327,\n",
       "                        0.0033,  0.0176, -0.0792, -0.0348, -0.0640,  0.0984,  0.0782,  0.0817,\n",
       "                        0.0189,  0.0606, -0.0006, -0.0439, -0.0082,  0.0595,  0.0052,  0.0797,\n",
       "                        0.0976, -0.0135, -0.0318, -0.0292,  0.0302, -0.0284,  0.0793, -0.0901,\n",
       "                       -0.0257, -0.0376,  0.0524,  0.0961,  0.0368,  0.0131, -0.0218, -0.0607,\n",
       "                       -0.0913,  0.0585,  0.0702, -0.0558,  0.0716, -0.0848, -0.0038, -0.0741,\n",
       "                        0.0182, -0.0476,  0.0819,  0.0591,  0.0782, -0.0748, -0.0992,  0.0033,\n",
       "                       -0.0538,  0.0364,  0.0446, -0.0009,  0.0971,  0.0774,  0.0382,  0.0247,\n",
       "                        0.0871, -0.0413,  0.0092,  0.0050, -0.0979,  0.0725,  0.0448, -0.0215,\n",
       "                       -0.0955, -0.0685, -0.0733,  0.0098],\n",
       "                      [-0.0786,  0.0851,  0.0023, -0.0129, -0.0264, -0.0098, -0.0716, -0.0386,\n",
       "                        0.0343, -0.0820, -0.0457,  0.0491, -0.0707,  0.0631, -0.0724, -0.0513,\n",
       "                       -0.0093,  0.0914,  0.0755,  0.0641, -0.0360, -0.0964, -0.0340,  0.0382,\n",
       "                        0.0901,  0.0468,  0.0269,  0.0381,  0.0498, -0.0635,  0.0069,  0.0511,\n",
       "                        0.0099,  0.0095, -0.0571, -0.0287, -0.0971, -0.0007,  0.0260,  0.0007,\n",
       "                       -0.0497,  0.0187, -0.0262,  0.0036, -0.0025, -0.0341,  0.0772,  0.0794,\n",
       "                       -0.0265,  0.0495, -0.0136, -0.0752,  0.0673, -0.0641,  0.0271,  0.0398,\n",
       "                        0.0619,  0.0623, -0.0094,  0.0149, -0.0853,  0.0929,  0.0505,  0.0065,\n",
       "                        0.0326,  0.0846,  0.0071,  0.0668,  0.0700, -0.0278, -0.0341, -0.0841,\n",
       "                       -0.0823,  0.0690,  0.0188,  0.0471,  0.0058,  0.0823, -0.0813,  0.0697,\n",
       "                        0.0793, -0.0606,  0.0464,  0.0957,  0.0148, -0.0537, -0.0435, -0.0687,\n",
       "                        0.0438, -0.0302,  0.0927, -0.0331, -0.0598,  0.0994, -0.0064,  0.0250,\n",
       "                        0.0503, -0.0165,  0.0812, -0.0834],\n",
       "                      [-0.0516,  0.0381, -0.0795,  0.0328,  0.0342,  0.0343,  0.0989, -0.0471,\n",
       "                       -0.0902, -0.0962, -0.0543, -0.0626,  0.0360, -0.0956, -0.0646,  0.0004,\n",
       "                        0.0301,  0.0429,  0.0472,  0.0006, -0.0988,  0.0223, -0.0877,  0.0078,\n",
       "                       -0.0853, -0.0673,  0.0718, -0.0965, -0.0304,  0.0583, -0.0268, -0.0860,\n",
       "                        0.0510,  0.0029,  0.0372,  0.0681, -0.0257, -0.0812,  0.0405,  0.0780,\n",
       "                        0.0018,  0.0573,  0.0888, -0.0673, -0.0899,  0.0113, -0.0014, -0.0601,\n",
       "                        0.0980, -0.0779,  0.0294, -0.0483, -0.0435, -0.0566,  0.0288,  0.0515,\n",
       "                        0.0255, -0.0635, -0.0251, -0.0139, -0.0622,  0.0427,  0.0988,  0.0830,\n",
       "                        0.0611, -0.0764,  0.0222,  0.0917,  0.0587, -0.0419,  0.0416, -0.0156,\n",
       "                        0.0766, -0.0002, -0.0778, -0.0441, -0.0305, -0.0953, -0.0649,  0.0279,\n",
       "                        0.0107, -0.0005, -0.0956,  0.0023,  0.0843,  0.0896,  0.0491, -0.0159,\n",
       "                        0.0072, -0.0065,  0.0530, -0.0527, -0.0887,  0.0360, -0.0002, -0.0877,\n",
       "                        0.0118,  0.0164, -0.0959, -0.0650],\n",
       "                      [ 0.0556,  0.0765,  0.0375, -0.0225, -0.0388,  0.0791, -0.0092,  0.0673,\n",
       "                        0.0546, -0.0202,  0.0551,  0.0351, -0.0499, -0.0219, -0.0630, -0.0334,\n",
       "                       -0.0626, -0.0729, -0.0821,  0.0772, -0.0335, -0.0073,  0.0553,  0.0305,\n",
       "                       -0.0586,  0.0320, -0.0420, -0.0673,  0.0951,  0.0566,  0.0566,  0.0327,\n",
       "                        0.0387, -0.0437, -0.0669, -0.0110, -0.0590, -0.0537, -0.0176, -0.0134,\n",
       "                       -0.0386, -0.0397, -0.0685,  0.0973,  0.0233,  0.0022,  0.0319, -0.0275,\n",
       "                        0.0445,  0.0913, -0.0595,  0.0435,  0.0676, -0.0183, -0.0102, -0.0145,\n",
       "                       -0.0804,  0.0676,  0.0833, -0.0815, -0.0696,  0.0005, -0.0696,  0.0454,\n",
       "                       -0.0848,  0.0247, -0.0757, -0.0098,  0.0179,  0.0004,  0.0739,  0.0755,\n",
       "                       -0.0710, -0.0290,  0.0737,  0.0979, -0.0889,  0.0464,  0.0761,  0.0926,\n",
       "                       -0.0789, -0.0662, -0.0162, -0.0927,  0.0910,  0.0734, -0.0322,  0.0934,\n",
       "                       -0.0514,  0.0550, -0.0859,  0.0491, -0.0439,  0.0350, -0.0766, -0.0775,\n",
       "                       -0.0670, -0.0898, -0.0802, -0.0251],\n",
       "                      [-0.0052, -0.0134,  0.0351,  0.0040, -0.0749,  0.0466,  0.0049,  0.0396,\n",
       "                        0.0453, -0.0673, -0.0379,  0.0824, -0.0045, -0.0954,  0.0570,  0.0253,\n",
       "                        0.0968,  0.0564,  0.0963,  0.0082, -0.0093, -0.0976, -0.0711, -0.0536,\n",
       "                       -0.0661, -0.0547, -0.0622,  0.0723,  0.0787,  0.0524,  0.0159,  0.0159,\n",
       "                        0.0953, -0.0696,  0.0323,  0.0780,  0.0964,  0.0062, -0.0403, -0.0347,\n",
       "                       -0.0469, -0.0450,  0.0968, -0.0127, -0.0884, -0.0528, -0.0291,  0.0008,\n",
       "                       -0.0966, -0.0429,  0.0564,  0.0178, -0.0569, -0.0700, -0.0663, -0.0654,\n",
       "                       -0.0522,  0.0888, -0.0980, -0.0941, -0.0109,  0.0986, -0.0345,  0.0337,\n",
       "                        0.0755, -0.0383,  0.0941, -0.0766, -0.0038, -0.0168,  0.0685, -0.0559,\n",
       "                        0.0118,  0.0054,  0.0390, -0.0926,  0.0446,  0.0810,  0.0260, -0.0002,\n",
       "                       -0.0382,  0.0630,  0.0304, -0.0611,  0.0783,  0.0056, -0.0986,  0.0442,\n",
       "                        0.0393,  0.0029,  0.0104,  0.0717,  0.0095,  0.0767, -0.0008,  0.0567,\n",
       "                       -0.0171, -0.0318,  0.0241,  0.0363],\n",
       "                      [-0.0394,  0.0168,  0.0835, -0.0652, -0.0253, -0.0116, -0.0588,  0.0655,\n",
       "                        0.0425,  0.0468,  0.0907,  0.0418, -0.0369, -0.0337, -0.0556,  0.0857,\n",
       "                        0.0632, -0.0276,  0.0718, -0.0081,  0.0741,  0.0280,  0.0192, -0.0388,\n",
       "                       -0.0121, -0.0151,  0.0449,  0.0049,  0.0927, -0.0677,  0.0812,  0.0392,\n",
       "                        0.0442,  0.0032, -0.0621,  0.0143,  0.0973, -0.0992, -0.0245, -0.0374,\n",
       "                       -0.0506, -0.0699, -0.0445, -0.0909,  0.0910, -0.0280,  0.0364,  0.0225,\n",
       "                       -0.0994, -0.0253, -0.0577,  0.0077, -0.0242, -0.0082, -0.0784, -0.0155,\n",
       "                        0.0830, -0.0935, -0.0289,  0.0892,  0.0148, -0.0110, -0.0141, -0.0032,\n",
       "                       -0.0324, -0.0855, -0.0810, -0.0703,  0.0183,  0.0870, -0.0804,  0.0477,\n",
       "                       -0.0874,  0.0828,  0.0729, -0.0789, -0.0031,  0.0607, -0.0124, -0.0424,\n",
       "                       -0.0955,  0.0278, -0.0533,  0.0967, -0.0911, -0.0994,  0.0108,  0.0037,\n",
       "                        0.0621,  0.0913,  0.0662, -0.0862,  0.0325,  0.0937,  0.0427, -0.0482,\n",
       "                        0.0071,  0.0373, -0.0073, -0.0067],\n",
       "                      [ 0.0687, -0.0709,  0.0087,  0.0242,  0.0493,  0.0346,  0.0632, -0.0569,\n",
       "                        0.0769, -0.0998,  0.0859, -0.0738,  0.0368, -0.0797,  0.0213, -0.0315,\n",
       "                       -0.0554,  0.0818, -0.0738, -0.0052, -0.0185,  0.0904,  0.0561,  0.0167,\n",
       "                        0.0253, -0.0240, -0.0884, -0.0601, -0.0346,  0.0459, -0.0988,  0.0577,\n",
       "                        0.0684, -0.0300, -0.0656, -0.0856,  0.0912,  0.0378, -0.0609, -0.0786,\n",
       "                        0.0510,  0.0498,  0.0059,  0.0850, -0.0997, -0.0715, -0.0817, -0.0782,\n",
       "                        0.0717,  0.0734,  0.0269, -0.0190,  0.0049,  0.0627,  0.0986,  0.0987,\n",
       "                       -0.0045, -0.0674,  0.0902, -0.0788, -0.0387,  0.0800, -0.0006, -0.0108,\n",
       "                       -0.0750,  0.0995,  0.0973,  0.0128, -0.0391,  0.0913,  0.0015,  0.0170,\n",
       "                        0.0162, -0.0680, -0.0901, -0.0477, -0.0015,  0.0872, -0.0305,  0.0408,\n",
       "                       -0.0272, -0.0271, -0.0846, -0.0610,  0.0645,  0.0155,  0.0094, -0.0815,\n",
       "                       -0.0328, -0.0351, -0.0361,  0.0687,  0.0475, -0.0806, -0.0721, -0.0630,\n",
       "                        0.0497, -0.0905,  0.0610, -0.0839],\n",
       "                      [-0.0991, -0.0983,  0.0729,  0.0490,  0.0528,  0.0084,  0.0070, -0.0084,\n",
       "                       -0.0699, -0.0047,  0.0212,  0.0047, -0.0122, -0.0005,  0.0509, -0.0774,\n",
       "                       -0.0355,  0.0004,  0.0370,  0.0357, -0.0483,  0.0565, -0.0446, -0.0203,\n",
       "                       -0.0660,  0.0641, -0.0009, -0.0400,  0.0500, -0.0501,  0.0563,  0.0083,\n",
       "                       -0.0443, -0.0216,  0.0213, -0.0881,  0.0532, -0.0934,  0.0049,  0.0837,\n",
       "                       -0.0239, -0.0043, -0.0608,  0.0166, -0.0336,  0.0444, -0.0287, -0.0042,\n",
       "                        0.0648,  0.0092,  0.0754,  0.0398, -0.0099, -0.0403, -0.0883,  0.0738,\n",
       "                       -0.0183, -0.0285, -0.0436,  0.0825,  0.0853, -0.0836,  0.0765, -0.0220,\n",
       "                       -0.0316, -0.0709,  0.0035, -0.0027,  0.0702,  0.0817, -0.0544,  0.0380,\n",
       "                        0.0230, -0.0703, -0.0577, -0.0133, -0.0891, -0.0995, -0.0771, -0.0518,\n",
       "                       -0.0051, -0.0536,  0.0688, -0.0220,  0.0171,  0.0065, -0.0284,  0.0055,\n",
       "                        0.0453,  0.0890,  0.0950, -0.0483, -0.0228,  0.0388,  0.0599, -0.0273,\n",
       "                       -0.0921, -0.0113, -0.0042,  0.0780],\n",
       "                      [-0.0426,  0.0102,  0.0569,  0.0562, -0.0226,  0.0703, -0.0514, -0.0136,\n",
       "                        0.0233, -0.0083, -0.0300, -0.0968, -0.0167, -0.0337, -0.0113, -0.0867,\n",
       "                        0.0365,  0.0459,  0.0896, -0.0791, -0.0293, -0.0878, -0.0716,  0.0955,\n",
       "                        0.0964,  0.0731, -0.0533, -0.0783,  0.0300, -0.0296,  0.0397, -0.0124,\n",
       "                        0.0640, -0.0889,  0.0855,  0.0885,  0.0482,  0.0546, -0.0136,  0.0113,\n",
       "                       -0.0962, -0.0714,  0.0585, -0.0514, -0.0272, -0.0107,  0.0567, -0.0931,\n",
       "                       -0.0490,  0.0154,  0.0473,  0.0888,  0.0788,  0.0473,  0.0920,  0.0914,\n",
       "                        0.0602,  0.0556, -0.0118, -0.0625, -0.0080,  0.0719,  0.0226,  0.0826,\n",
       "                        0.0150,  0.0860, -0.0945, -0.0410,  0.0512, -0.0726, -0.0102,  0.0112,\n",
       "                        0.0679,  0.0056,  0.0731,  0.0447, -0.0698, -0.0859, -0.0821,  0.0890,\n",
       "                       -0.0921, -0.0386,  0.0307, -0.0619,  0.0581, -0.0966, -0.0984,  0.0825,\n",
       "                       -0.0609,  0.0399, -0.0422,  0.0971, -0.0861, -0.0911, -0.0707, -0.0833,\n",
       "                        0.0621,  0.0757,  0.0586, -0.0722],\n",
       "                      [ 0.0444,  0.0952, -0.0479, -0.0254,  0.0646, -0.0376,  0.0055, -0.0737,\n",
       "                        0.0909,  0.0891, -0.0501, -0.0945,  0.0969, -0.0313, -0.0773,  0.0605,\n",
       "                        0.0602,  0.0471,  0.0414,  0.0375,  0.0844, -0.0436, -0.0220,  0.0138,\n",
       "                       -0.0427,  0.0573,  0.0447,  0.0155,  0.0206,  0.0018, -0.0574, -0.0849,\n",
       "                       -0.0701,  0.0371,  0.0235,  0.0804, -0.0513, -0.0695,  0.0570,  0.0543,\n",
       "                       -0.0493, -0.0915, -0.0962,  0.0986,  0.0431,  0.0517, -0.0158, -0.0601,\n",
       "                       -0.0666,  0.0089, -0.0820, -0.0985,  0.0925,  0.0005, -0.0997,  0.0688,\n",
       "                        0.0487,  0.0573, -0.0230, -0.0683,  0.0625, -0.0492,  0.0721,  0.0926,\n",
       "                        0.0805, -0.0912,  0.0060,  0.0939,  0.0045, -0.0710, -0.0246,  0.0658,\n",
       "                       -0.0665, -0.0932, -0.0886, -0.0260, -0.0332,  0.0528, -0.0763, -0.0097,\n",
       "                       -0.0738,  0.0151,  0.0712, -0.0721,  0.0687, -0.0933, -0.0914, -0.0081,\n",
       "                        0.0444,  0.0198, -0.0730,  0.0477,  0.0103,  0.0820, -0.0611, -0.0003,\n",
       "                       -0.0510, -0.0452,  0.0075,  0.0983]])),\n",
       "             ('linear_relu_stack.4.bias',\n",
       "              tensor([ 0.0280, -0.0960,  0.0731, -0.0127,  0.0094,  0.0376, -0.0396,  0.0637,\n",
       "                       0.0508,  0.0566]))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "\n",
    "pytorch的训练需要自行实现，包括\n",
    "1. 定义损失函数\n",
    "2. 定义优化器\n",
    "3. 定义训练步\n",
    "4. 训练"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.639838300Z",
     "start_time": "2026-02-08T18:46:32.286023Z"
    }
   },
   "source": [
    "# 1. 定义损失函数 采用交叉熵损失\n",
    "loss_fct = nn.CrossEntropyLoss() #内部先做softmax，然后计算交叉熵\n",
    "# 2. 定义优化器 采用SGD\n",
    "# Optimizers specified in the torch.optim package,随机梯度下降\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.640840600Z",
     "start_time": "2026-02-08T18:46:36.756334Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "@torch.no_grad() # 装饰器，禁止反向传播，节省内存\n",
    "def evaluating(model, dataloader, loss_fct):\n",
    "    loss_list = [] # 记录损失\n",
    "    pred_list = [] # 记录预测\n",
    "    label_list = [] # 记录标签\n",
    "    for datas, labels in dataloader:#10000/32=312\n",
    "        datas = datas.to(device) # 转到GPU\n",
    "        labels = labels.to(device) # 转到GPU\n",
    "        # 前向计算\n",
    "        logits = model(datas)\n",
    "        loss = loss_fct(logits, labels)         # 验证集损失\n",
    "        loss_list.append(loss.item()) # 记录损失\n",
    "        \n",
    "        preds = logits.argmax(axis=-1)    # 验证集预测,argmax返回最大值索引\n",
    "        # print(preds)\n",
    "        pred_list.extend(preds.cpu().numpy().tolist())#将PyTorch张量转换为NumPy数组。只有当张量在CPU上时，这个转换才是合法的\n",
    "        # print(preds.cpu().numpy().tolist())\n",
    "        label_list.extend(labels.cpu().numpy().tolist())\n",
    "        \n",
    "    acc = accuracy_score(label_list, pred_list) # 计算准确率\n",
    "    return np.mean(loss_list), acc\n"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "source": [
    "1875*20"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.646107700Z",
     "start_time": "2026-02-08T18:47:19.878103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37500"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T18:35:03.363058Z",
     "start_time": "2026-02-09T18:35:03.185676Z"
    }
   },
   "source": [
    "# 训练\n",
    "def training(model, train_loader, val_loader, epoch, loss_fct, optimizer, eval_step=500):\n",
    "    record_dict = {\n",
    "        \"train\": [],\n",
    "        \"val\": []\n",
    "    }\n",
    "    \n",
    "    global_step = 0\n",
    "    model.train()\n",
    "    with tqdm(total=epoch * len(train_loader)) as pbar: # 进度条 1875*20,60000/32=1875\n",
    "        for epoch_id in range(epoch): # 训练epoch次\n",
    "            # training\n",
    "            for datas, labels in train_loader: #执行次数是60000/32=1875\n",
    "                datas = datas.to(device) #datas尺寸是[batch_size,1,28,28]\n",
    "                labels = labels.to(device) #labels尺寸是[batch_size]\n",
    "                # 梯度清空\n",
    "                optimizer.zero_grad()\n",
    "                # 模型前向计算\n",
    "                logits = model(datas)\n",
    "                # 计算损失\n",
    "                loss = loss_fct(logits, labels)\n",
    "                # 梯度回传，loss.backward()会计算梯度，loss对模型参数求导\n",
    "                loss.backward()\n",
    "                # 调整优化器，包括学习率的变动等,优化器的学习率会随着训练的进行而减小，更新w,b\n",
    "                optimizer.step() #梯度是计算并存储在模型参数的 .grad 属性中，优化器使用这些存储的梯度来更新模型参数\n",
    "\n",
    "                preds = logits.argmax(axis=-1) # 训练集预测\n",
    "                acc = accuracy_score(labels.cpu().numpy(), preds.cpu().numpy())   # 计算准确率，numpy可以\n",
    "                loss = loss.cpu().item() # 损失转到CPU，item()取值,一个数值\n",
    "                # record\n",
    "                \n",
    "                record_dict[\"train\"].append({\n",
    "                    \"loss\": loss, \"acc\": acc, \"step\": global_step\n",
    "                }) # 记录训练集信息，每一步的损失，准确率，步数\n",
    "                \n",
    "                # evaluating\n",
    "                if global_step % eval_step == 0:\n",
    "                    model.eval() # 进入评估模式\n",
    "                    val_loss, val_acc = evaluating(model, val_loader, loss_fct)\n",
    "                    record_dict[\"val\"].append({\n",
    "                        \"loss\": val_loss, \"acc\": val_acc, \"step\": global_step\n",
    "                    })\n",
    "                    model.train() # 进入训练模式\n",
    "\n",
    "                # udate step\n",
    "                global_step += 1 # 全局步数加1\n",
    "                pbar.update(1) # 更新进度条\n",
    "                pbar.set_postfix({\"epoch\": epoch_id}) # 设置进度条显示信息\n",
    "        \n",
    "    return record_dict\n",
    "        \n",
    "\n",
    "epoch = 20 #改为40\n",
    "model = model.to(device)\n",
    "record = training(model, train_loader, val_loader, epoch, loss_fct, optimizer, eval_step=1000)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 55\u001B[0m\n\u001B[0;32m     53\u001B[0m epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m20\u001B[39m \u001B[38;5;66;03m#改为40\u001B[39;00m\n\u001B[0;32m     54\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 55\u001B[0m record \u001B[38;5;241m=\u001B[39m training(model, train_loader, val_loader, epoch, loss_fct, optimizer, eval_step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "record[\"train\"][-5:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.649107700Z",
     "start_time": "2026-02-08T18:47:03.189183Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[46], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m record[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m5\u001B[39m:]\n",
      "\u001B[1;31mNameError\u001B[0m: name 'record' is not defined"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'loss': 0.36084355672184654, 'acc': 0.8712, 'step': 33000},\n {'loss': 0.35720211475754315, 'acc': 0.8724, 'step': 34000},\n {'loss': 0.36683890228263866, 'acc': 0.8709, 'step': 35000},\n {'loss': 0.36297369616243025, 'acc': 0.8713, 'step': 36000},\n {'loss': 0.35757329757697287, 'acc': 0.874, 'step': 37000}]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[\"val\"][-5:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.650108Z",
     "start_time": "2024-07-17T03:19:46.377355Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.651108100Z",
     "start_time": "2026-02-08T18:48:18.942574Z"
    }
   },
   "source": [
    "#画线要注意的是损失是不一定在零到1之间的\n",
    "def plot_learning_curves(record_dict, sample_step=1000):\n",
    "    # build DataFrame\n",
    "    train_df = pd.DataFrame(record_dict[\"train\"]).set_index(\"step\").iloc[::sample_step]\n",
    "    val_df = pd.DataFrame(record_dict[\"val\"]).set_index(\"step\")\n",
    "    last_step = train_df.index[-1] # 最后一步的步数\n",
    "    # print(train_df.columns)\n",
    "    print(train_df['acc'])\n",
    "    print(val_df['acc'])\n",
    "    # plot\n",
    "    fig_num = len(train_df.columns) # 画几张图,分别是损失和准确率\n",
    "    fig, axs = plt.subplots(1, fig_num, figsize=(5 * fig_num, 5))\n",
    "    for idx, item in enumerate(train_df.columns):\n",
    "        # print(train_df[item].values)\n",
    "        axs[idx].plot(train_df.index, train_df[item], label=f\"train_{item}\")\n",
    "        axs[idx].plot(val_df.index, val_df[item], label=f\"val_{item}\")\n",
    "        axs[idx].grid() # 显示网格\n",
    "        axs[idx].legend() # 显示图例\n",
    "        axs[idx].set_xticks(range(0, train_df.index[-1], 5000)) # 设置x轴刻度\n",
    "        axs[idx].set_xticklabels(map(lambda x: f\"{int(x/1000)}k\", range(0, last_step, 5000))) # 设置x轴标签\n",
    "        axs[idx].set_xlabel(\"step\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(record)  #横坐标是 steps"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 25\u001B[0m\n\u001B[0;32m     21\u001B[0m         axs[idx]\u001B[38;5;241m.\u001B[39mset_xlabel(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstep\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     23\u001B[0m     plt\u001B[38;5;241m.\u001B[39mshow()\n\u001B[1;32m---> 25\u001B[0m plot_learning_curves(record)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'record' is not defined"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T17:41:35.652108900Z",
     "start_time": "2026-02-08T18:48:25.023237Z"
    }
   },
   "source": [
    "# dataload for evaluating\n",
    "\n",
    "model.eval() # 进入评估模式\n",
    "loss, acc = evaluating(model, val_loader, loss_fct)\n",
    "print(f\"loss:     {loss:.4f}\\naccuracy: {acc:.4f}\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# dataload for evaluating\u001B[39;00m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39meval() \u001B[38;5;66;03m# 进入评估模式\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m loss, acc \u001B[38;5;241m=\u001B[39m evaluating(model, val_loader, loss_fct)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mloss:     \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mloss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124maccuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00macc\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T18:31:52.497885Z",
     "start_time": "2026-02-09T18:31:36.603205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# 包装一个 range 或任何可迭代对象\n",
    "for i in tqdm(range(1000)):\n",
    "    time.sleep(0.1)  # 模拟耗时操作"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 156/1000 [00:15<01:25,  9.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# 包装一个 range 或任何可迭代对象\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1000\u001B[39m)):\n\u001B[1;32m----> 6\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m0.1\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
